"""
üåø‚ú® Emotime Demo Test ‚Äî –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã

–ü—Ä–æ—Å—Ç–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Emotime.
"""

import asyncio
from datetime import datetime

from .core import EmotimeEngine
from .sensors import SensorData, SensorType, TextData, TouchData, AudioData
from .utils import safe_logger


async def demo_emotional_journey():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è."""
    safe_logger.info("Starting Emotime demo...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∏–∂–æ–∫
    engine = EmotimeEngine(
        user_id="demo_user",
        session_id="demo_session",
        update_interval=1.0,  # 1 —Å–µ–∫—É–Ω–¥–∞ –º–µ–∂–¥—É –æ–±—Ä–∞–±–æ—Ç–∫–∞–º–∏
        enable_neo4j=False,   # –û—Ç–∫–ª—é—á–∞–µ–º Neo4j –¥–ª—è –¥–µ–º–æ
        trace_window=10
    )
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–≤–∏–∂–æ–∫
        await engine.start()
        safe_logger.info("Engine started - beginning emotional journey...")
        
        # –§–∞–∑–∞ 1: –°–ø–æ–∫–æ–π–Ω–æ–µ —É—Ç—Ä–æ
        safe_logger.info("Phase 1: Calm morning...")
        
        calm_texts = [
            "Good morning, feeling peaceful today",
            "Starting with meditation and tea",
            "The world feels quiet and serene"
        ]
        
        for text in calm_texts:
            text_data = TextData(
                text=text,
                word_count=len(text.split()),
                char_count=len(text)
            )
            
            sensor_data = SensorData(
                sensor_type=SensorType.TEXT,
                timestamp=datetime.now(),
                raw_data=text_data,
                metadata={"phase": "calm"}
            )
            
            await engine.process_sensor_data(sensor_data)
            await asyncio.sleep(2)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            state = await engine.get_current_state()
            if state:
                safe_logger.info(f"Current mode: {state.mode.name} (confidence: {state.confidence:.2f})")
        
        # –§–∞–∑–∞ 2: –†–∞–±–æ—á–∏–π —Ñ–æ–∫—É—Å
        safe_logger.info("Phase 2: Work focus...")
        
        focus_data = [
            ("I need to concentrate on this important project", SensorType.TEXT),
            ("Deep work session starting now", SensorType.TEXT),
        ]
        
        for text, sensor_type in focus_data:
            if sensor_type == SensorType.TEXT:
                text_data = TextData(
                    text=text,
                    word_count=len(text.split()),
                    char_count=len(text)
                )
                raw_data = text_data
            
            sensor_data = SensorData(
                sensor_type=sensor_type,
                timestamp=datetime.now(),
                raw_data=raw_data,
                metadata={"phase": "focus"}
            )
            
            await engine.process_sensor_data(sensor_data)
            await asyncio.sleep(2)
            
            state = await engine.get_current_state()
            if state:
                safe_logger.info(f"Current mode: {state.mode.name} (confidence: {state.confidence:.2f})")
        
        # –§–∞–∑–∞ 3: –°—Ç—Ä–µ—Å—Å–æ–≤—ã–π –ø–∏–∫
        safe_logger.info("Phase 3: Stress peak...")
        
        stress_inputs = [
            ("URGENT DEADLINE!!! So much pressure!", SensorType.TEXT, None),
            (None, SensorType.TOUCH, TouchData(pressure=0.9, duration=0.2, frequency=8.0, pattern="rapid_taps")),
            (None, SensorType.AUDIO, AudioData(
                pitch_mean=0.8, pitch_variance=0.4, speech_rate=180.0,
                volume_level=0.9, pause_ratio=0.05, emotion_markers=["stress", "urgency"]
            ))
        ]
        
        for text, sensor_type, touch_audio_data in stress_inputs:
            if sensor_type == SensorType.TEXT:
                raw_data = TextData(text=text, word_count=len(text.split()), char_count=len(text))
            else:
                raw_data = touch_audio_data
            
            sensor_data = SensorData(
                sensor_type=sensor_type,
                timestamp=datetime.now(),
                raw_data=raw_data,
                metadata={"phase": "stress"}
            )
            
            await engine.process_sensor_data(sensor_data)
            await asyncio.sleep(2)
            
            state = await engine.get_current_state()
            if state:
                safe_logger.info(f"Current mode: {state.mode.name} (confidence: {state.confidence:.2f})")
        
        # –§–∞–∑–∞ 4: –†–∞–¥–æ—Å—Ç–Ω—ã–π –ø—Ä–æ—Ä—ã–≤
        safe_logger.info("Phase 4: Joy breakthrough...")
        
        joy_texts = [
            "YES! Finally solved it! This is amazing!",
            "I feel so happy and accomplished right now",
            "What a wonderful feeling of success!"
        ]
        
        for text in joy_texts:
            text_data = TextData(
                text=text,
                word_count=len(text.split()),
                char_count=len(text)
            )
            
            sensor_data = SensorData(
                sensor_type=SensorType.TEXT,
                timestamp=datetime.now(),
                raw_data=text_data,
                metadata={"phase": "joy"}
            )
            
            await engine.process_sensor_data(sensor_data)
            await asyncio.sleep(2)
            
            state = await engine.get_current_state()
            if state:
                safe_logger.info(f"Current mode: {state.mode.name} (confidence: {state.confidence:.2f})")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        safe_logger.info("Getting emotional insights...")
        insights = await engine.get_emotional_insights()
        
        safe_logger.info("=== EMOTIONAL JOURNEY COMPLETE ===")
        safe_logger.info(f"Final state: {insights['current_state']['status']}")
        
        if insights['current_state']['status'] == 'active':
            current = insights['current_state']
            safe_logger.info(f"Final mode: {current['mode']['name']}")
            safe_logger.info(f"Final confidence: {current['confidence']:.2f}")
            safe_logger.info(f"Trace points collected: {current['trace_points']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–µ–¥
        trace = await engine.get_resonance_trace()
        safe_logger.info(f"Resonance trace length: {len(trace)} points")
        
        if trace:
            safe_logger.info("Recent emotional trajectory:")
            for i, point in enumerate(trace[-5:]):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Ç–æ—á–µ–∫
                safe_logger.info(f"  Point {i+1}: valence={point.valence:.2f}, arousal={point.arousal:.2f}")
        
    except Exception as e:
        safe_logger.error(f"Demo error: {e}")
        
    finally:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
        await engine.stop()
        safe_logger.info("Demo completed - engine stopped")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ."""
    try:
        await demo_emotional_journey()
    except KeyboardInterrupt:
        safe_logger.info("Demo interrupted by user")
    except Exception as e:
        safe_logger.error(f"Demo failed: {e}")


if __name__ == "__main__":
    print("[leaf][sparkle] Emotime Demo Starting...")
    print("Press Ctrl+C to stop\n")
    
    asyncio.run(main())