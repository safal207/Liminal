"""
üåø‚ú® Emotime API Endpoints ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LIMINAL API

API —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π Emotime:
- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–µ–Ω—Å–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö  
- –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
- –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏—è–º–∏

"–ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å ‚Äî —ç—Ç–æ –ø—Ä–∏–∫–æ—Å–Ω–æ–≤–µ–Ω–∏–µ –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É —Ä–∏—Ç–º—É –¥—É—à–∏"
"""

from datetime import datetime
from typing import Dict, List, Optional, Any
from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel, Field

from .core import EmotimeEngine
from .sensors import TextSensor, TouchSensor, AudioSensor, SensorType
from .cache import emotime_cache
from ..performance.batch_processor import emotime_batch_processor
from ..performance.connection_optimizations import connection_manager
import asyncio
import hashlib


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä Emotime (–≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏)
_global_emotime: Optional[EmotimeEngine] = None

# Performance optimization settings
USE_CACHING = True
USE_BATCH_PROCESSING = True
CACHE_TTL = 300  # 5 minutes
BATCH_SIZE = 5
BATCH_TIMEOUT = 0.5


def get_emotime_engine(user_id: str = "default") -> EmotimeEngine:
    """–ü–æ–ª—É—á–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä Emotime –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    global _global_emotime
    if not _global_emotime or _global_emotime.user_id != user_id:
        _global_emotime = EmotimeEngine(user_id=user_id)
        # –ê–≤—Ç–æ–∑–∞–ø—É—Å–∫ –≤ production –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∏–Ω–∞—á–µ
        # await _global_emotime.start()
    return _global_emotime


# Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è API

class TextInput(BaseModel):
    """–¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
    text: str = Field(..., description="–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è")
    typing_speed: Optional[float] = Field(None, description="–°–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏ (—Å–∏–º–≤–æ–ª–æ–≤/—Å–µ–∫)")
    user_id: str = Field("default", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")


class TouchInput(BaseModel):
    """–î–∞–Ω–Ω—ã–µ –∫–∞—Å–∞–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
    pressure: float = Field(..., ge=0.0, le=1.0, description="–î–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Å–∞–Ω–∏—è (0.0-1.0)")
    duration: float = Field(..., gt=0, description="–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞—Å–∞–Ω–∏—è (—Å–µ–∫—É–Ω–¥—ã)")
    pattern: str = Field("tap", description="–ü–∞—Ç—Ç–µ—Ä–Ω –∫–∞—Å–∞–Ω–∏—è")
    coordinates: Optional[tuple] = Field(None, description="–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–∞—Å–∞–Ω–∏—è")
    user_id: str = Field("default", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")


class AudioInput(BaseModel):
    """–ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞."""
    pitch_mean: float = Field(..., description="–°—Ä–µ–¥–Ω—è—è —á–∞—Å—Ç–æ—Ç–∞ –≥–æ–ª–æ—Å–∞")
    pitch_variance: float = Field(..., description="–í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç–æ–Ω–∞")
    speech_rate: float = Field(..., description="–°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ (—Å–ª–æ–≤/–º–∏–Ω)")
    volume_level: float = Field(..., ge=0.0, le=1.0, description="–£—Ä–æ–≤–µ–Ω—å –≥—Ä–æ–º–∫–æ—Å—Ç–∏")
    pause_ratio: float = Field(..., ge=0.0, le=1.0, description="–î–æ–ª—è –ø–∞—É–∑")
    emotion_markers: List[str] = Field([], description="–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã")
    user_id: str = Field("default", description="ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")


class EmotimeStatus(BaseModel):
    """–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã Emotime."""
    status: str
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    timestamp: Optional[str] = None
    mode: Optional[Dict[str, Any]] = None
    features: Optional[Dict[str, Any]] = None  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ Any –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤
    confidence: Optional[float] = None
    trace_points: Optional[int] = None
    storage_enabled: Optional[bool] = None


class EmotimeInsights(BaseModel):
    """–ì–ª—É–±–æ–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã Emotime."""
    current_state: Dict[str, Any]
    timeseries_analysis: Dict[str, Any]
    mode_statistics: Dict[str, Any]
    mode_insights: List[str]
    fusion_statistics: Dict[str, Any]
    historical_patterns: Optional[Dict[str, Any]] = None


# –°–æ–∑–¥–∞–µ–º —Ä–æ—É—Ç–µ—Ä
emotime_router = APIRouter(prefix="/emotime", tags=["Emotime üåø‚ú®"])


@emotime_router.post("/text", response_model=Dict[str, Any])
async def process_text(input_data: TextInput):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
    - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ —Ç–µ–∫—Å—Ç–µ
    - –°–∫–æ—Ä–æ—Å—Ç—å –ø–µ—á–∞—Ç–∏ –∏ –ø–∞—É–∑—ã
    - –°—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    
    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ç–µ–∫—Å—Ç–æ–≤
    - –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è throughput
    
    Security:
    - Input sanitization –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    - –í–∞–ª–∏–¥–∞—Ü–∏—è user_id
    """
    try:
        # Security: Sanitize input data
        from .security.validators import get_input_sanitizer
        sanitizer = get_input_sanitizer()
        
        # Validate and sanitize user_id
        clean_user_id = sanitizer.validate_user_id(input_data.user_id)
        
        # Sanitize text content  
        clean_text = sanitizer.sanitize_text(input_data.text)
        
        # Create sanitized input data
        sanitized_input = TextInput(
            text=clean_text,
            typing_speed=input_data.typing_speed,
            pause_duration=input_data.pause_duration, 
            user_id=clean_user_id
        )
        # Performance optimization: check cache first  
        if USE_CACHING:
            cache_key = emotime_cache.get_cache_key(sanitized_input.text, sanitized_input.user_id)
            cached_result = emotime_cache.get(cache_key)
            
            if cached_result:
                return {
                    "status": "processed",
                    "sensor_type": "text", 
                    "timestamp": datetime.now().isoformat(),
                    "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–µ–∫—Å—Ç (cached): '{sanitized_input.text[:50]}...'",
                    "cached": True,
                    **cached_result
                }
        
        # Get Emotime engine
        emotime = get_emotime_engine(sanitized_input.user_id)
        
        # Performance optimization: use batch processing if enabled
        if USE_BATCH_PROCESSING:
            batch_data = {
                "text": sanitized_input.text,
                "user_id": sanitized_input.user_id,
                "typing_speed": sanitized_input.typing_speed,
                "type": "text"
            }
            
            batch_result = await emotime_batch_processor.add_request(
                request_id=f"text_{hash(sanitized_input.text)}_{sanitized_input.user_id}",
                data=batch_data
            )
            
            # Cache the result
            if USE_CACHING and batch_result:
                emotime_cache.set(cache_key, batch_result, CACHE_TTL)
            
            return {
                "status": "processed",
                "sensor_type": "text",
                "timestamp": datetime.now().isoformat(),
                "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–µ–∫—Å—Ç (batch): '{input_data.text[:50]}...'",
                "batch_processed": True,
                **batch_result
            }
        
        # Standard processing fallback
        text_sensor = TextSensor()
        metadata = {}
        if input_data.typing_speed:
            metadata["typing_speed"] = input_data.typing_speed
            
        sensor_data = await text_sensor.process(input_data.text, metadata)
        await emotime.process_sensor_data(sensor_data)
        
        # Get current state for response
        current_state = await emotime.get_current_state()
        result = {
            "status": "processed",
            "sensor_type": "text",
            "timestamp": sensor_data.timestamp.isoformat(),
            "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–µ–∫—Å—Ç: '{input_data.text[:50]}...'"
        }
        
        # Add emotional features if available
        if current_state:
            result["emotional_features"] = {
                "valence": current_state.features.valence,
                "arousal": current_state.features.arousal,
                "dominance": current_state.features.dominance,
                "confidence": current_state.features.confidence
            }
            result["confidence"] = current_state.confidence
            result["mode"] = {
                "name": current_state.mode.name,
                "type": current_state.mode.type.value
            }
        
        # Cache successful result
        if USE_CACHING:
            emotime_cache.set(cache_key, result, CACHE_TTL)
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Text processing failed: {str(e)}")


@emotime_router.post("/touch", response_model=Dict[str, str]) 
async def process_touch(input_data: TouchInput):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∫–∞—Å–∞–Ω–∏–π –¥–ª—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
    - –î–∞–≤–ª–µ–Ω–∏–µ –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞—Å–∞–Ω–∏–π
    - –ß–∞—Å—Ç–æ—Ç—É –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
    - –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∂–µ—Å—Ç–æ–≤
    """
    try:
        emotime = get_emotime_engine(input_data.user_id)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞—á-—Å–µ–Ω—Å–æ—Ä
        touch_sensor = TouchSensor()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞—Å–∞–Ω–∏–µ
        sensor_data = await touch_sensor.process(
            pressure=input_data.pressure,
            duration=input_data.duration,
            pattern=input_data.pattern,
            coordinates=input_data.coordinates
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Emotime
        await emotime.process_sensor_data(sensor_data)
        
        return {
            "status": "processed", 
            "sensor_type": "touch",
            "timestamp": sensor_data.timestamp.isoformat(),
            "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–∞—Å–∞–Ω–∏–µ: {input_data.pattern} ({input_data.pressure:.2f} pressure)"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Touch processing failed: {str(e)}")


@emotime_router.post("/audio", response_model=Dict[str, str])
async def process_audio(input_data: AudioInput):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç:
    - –¢–æ–Ω –∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é –≥–æ–ª–æ—Å–∞
    - –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏ –∏ –ø–∞—É–∑—ã
    - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –≤ —Ä–µ—á–∏
    """
    try:
        emotime = get_emotime_engine(input_data.user_id)
        
        # –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ —Å–µ–Ω—Å–æ—Ä
        audio_sensor = AudioSensor()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
        sensor_data = await audio_sensor.process(
            pitch_mean=input_data.pitch_mean,
            pitch_variance=input_data.pitch_variance,
            speech_rate=input_data.speech_rate,
            volume_level=input_data.volume_level,
            pause_ratio=input_data.pause_ratio,
            emotion_markers=input_data.emotion_markers
        )
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Emotime
        await emotime.process_sensor_data(sensor_data)
        
        return {
            "status": "processed",
            "sensor_type": "audio", 
            "timestamp": sensor_data.timestamp.isoformat(),
            "message": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∞—É–¥–∏–æ: {input_data.speech_rate:.1f} wpm, {len(input_data.emotion_markers)} –º–∞—Ä–∫–µ—Ä–æ–≤"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Audio processing failed: {str(e)}")


@emotime_router.get("/status", response_model=EmotimeStatus)
async def get_status(user_id: str = "default"):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - –¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º (—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ, —Ñ–æ–∫—É—Å, —Å—Ç—Ä–µ—Å—Å, –∏ —Ç.–¥.)
    - –≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    - –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    try:
        emotime = get_emotime_engine(user_id)
        status_data = emotime.to_dict()
        
        return EmotimeStatus(**status_data)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Status retrieval failed: {str(e)}")


@emotime_router.get("/insights", response_model=EmotimeInsights)
async def get_insights(user_id: str = "default"):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≥–ª—É–±–æ–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã –æ–± —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏.
    
    –í–∫–ª—é—á–∞–µ—Ç:
    - –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ –∏ —Ç—Ä–µ–Ω–¥–æ–≤
    - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
    - –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è  
    - –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ Neo4j
    """
    try:
        emotime = get_emotime_engine(user_id)
        insights_data = await emotime.get_emotional_insights()
        
        return EmotimeInsights(**insights_data)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Insights retrieval failed: {str(e)}")


@emotime_router.get("/timeline")
async def get_timeline(
    user_id: str = "default",
    session_id: Optional[str] = None,
    limit: int = 50
):
    """
    –ü–æ–ª—É—á–∞–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫
    —Å –∏—Ö —Ä–µ–∂–∏–º–∞–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏.
    """
    try:
        emotime = get_emotime_engine(user_id)
        
        if not emotime.storage:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏
            recent_points = emotime.get_resonance_trace(limit)
            return {
                "source": "memory", 
                "user_id": user_id,
                "points": [
                    {
                        "timestamp": point.timestamp.isoformat(),
                        "valence": point.valence,
                        "arousal": point.arousal,
                        "trend": point.trend,
                        "is_peak": point.is_peak
                    }
                    for point in recent_points
                ]
            }
        else:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Neo4j
            timeline = await emotime.storage.get_emotional_timeline(
                user_id=user_id,
                session_id=session_id, 
                limit=limit
            )
            return {
                "source": "neo4j",
                "user_id": user_id,
                "session_id": session_id,
                "timeline": timeline
            }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Timeline retrieval failed: {str(e)}")


@emotime_router.post("/session/start")
async def start_session(user_id: str = "default"):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—É—é —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    
    –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –¥–≤–∏–∂–æ–∫ Emotime –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.
    """
    try:
        global _global_emotime
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å–µ—Å—Å–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if _global_emotime:
            await _global_emotime.stop()
            
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é
        _global_emotime = EmotimeEngine(user_id=user_id)
        await _global_emotime.start()
        
        return {
            "status": "started",
            "user_id": user_id,
            "session_id": _global_emotime.session_id,
            "timestamp": datetime.now().isoformat(),
            "message": "üíì Emotime session started ‚Äî —Å–µ—Ä–¥—Ü–µ –Ω–∞—á–∏–Ω–∞–µ—Ç –±–∏—Ç—å—Å—è"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Session start failed: {str(e)}")


@emotime_router.post("/session/stop")
async def stop_session(user_id: str = "default"):
    """
    –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—É—â—É—é —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é.
    
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.
    """
    try:
        global _global_emotime
        
        if _global_emotime and _global_emotime.user_id == user_id:
            session_id = _global_emotime.session_id
            await _global_emotime.stop()
            _global_emotime = None
            
            return {
                "status": "stopped",
                "user_id": user_id, 
                "session_id": session_id,
                "timestamp": datetime.now().isoformat(),
                "message": "üåø Emotime session stopped ‚Äî —Å–µ—Ä–¥—Ü–µ –∑–∞–º–∏—Ä–∞–µ—Ç"
            }
        else:
            return {
                "status": "no_active_session",
                "user_id": user_id,
                "message": "–ê–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Session stop failed: {str(e)}")


@emotime_router.get("/health")
async def health_check():
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è Emotime —Å–∏—Å—Ç–µ–º—ã.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤.
    """
    try:
        global _global_emotime
        
        health_status = {
            "emotime_core": "ok",
            "active_session": _global_emotime is not None,
            "neo4j_storage": False,
            "prometheus_metrics": False,
            "timestamp": datetime.now().isoformat()
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Neo4j
        if _global_emotime and _global_emotime.storage:
            health_status["neo4j_storage"] = _global_emotime.storage.driver is not None
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        try:
            from .metrics_integration import METRICS_AVAILABLE
            health_status["prometheus_metrics"] = METRICS_AVAILABLE
        except ImportError:
            pass
            
        return health_status
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Health check failed: {str(e)}")


@emotime_router.get("/demo")
async def demo_data():
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Emotime.
    
    –°–æ–∑–¥–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Å–µ–Ω—Å–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã.
    """
    demo_scenarios = [
        {
            "name": "–°–ø–æ–∫–æ–π–Ω–æ–µ —É—Ç—Ä–æ",
            "text_data": {
                "text": "–î–æ–±—Ä–æ–µ —É—Ç—Ä–æ! –°–µ–≥–æ–¥–Ω—è –ø—Ä–µ–∫—Ä–∞—Å–Ω—ã–π –¥–µ–Ω—å –¥–ª—è —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π.",
                "typing_speed": 4.5
            },
            "touch_data": {
                "pressure": 0.3,
                "duration": 1.2,
                "pattern": "tap"
            },
            "expected_mode": "calm"
        },
        {
            "name": "–†–∞–±–æ—á–∏–π —Ñ–æ–∫—É—Å", 
            "text_data": {
                "text": "–ù—É–∂–Ω–æ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —ç—Ç–æ–π –∑–∞–¥–∞—á–µ –∏ –¥–æ–≤–µ—Å—Ç–∏ –µ–µ –¥–æ –∫–æ–Ω—Ü–∞.",
                "typing_speed": 8.2
            },
            "touch_data": {
                "pressure": 0.7,
                "duration": 0.5, 
                "pattern": "tap"
            },
            "expected_mode": "focus"
        },
        {
            "name": "–°—Ç—Ä–µ—Å—Å–æ–≤–∞—è —Å–∏—Ç—É–∞—Ü–∏—è",
            "text_data": {
                "text": "–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –∫–æ—à–º–∞—Ä! –ù–µ –∑–Ω–∞—é, –∫–∞–∫ —Å–æ –≤—Å–µ–º —ç—Ç–∏–º —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è!!!",
                "typing_speed": 12.1
            },
            "touch_data": {
                "pressure": 0.9,
                "duration": 0.2,
                "pattern": "gesture"
            },
            "expected_mode": "stress"
        },
        {
            "name": "–†–∞–¥–æ—Å—Ç–Ω—ã–π –º–æ–º–µ–Ω—Ç",
            "text_data": {
                "text": "–£—Ä–∞! –ü–æ–ª—É—á–∏–ª–æ—Å—å! –Ø —Ç–∞–∫ —Å—á–∞—Å—Ç–ª–∏–≤–∞, —á—Ç–æ –≤—Å–µ —Å–ª–æ–∂–∏–ª–æ—Å—å –æ—Ç–ª–∏—á–Ω–æ! ‚ú®",
                "typing_speed": 6.8
            },
            "touch_data": {
                "pressure": 0.5,
                "duration": 0.8,
                "pattern": "swipe" 
            },
            "expected_mode": "joy"
        }
    ]
    
    return {
        "message": "Emotime demo scenarios ready",
        "scenarios": demo_scenarios,
        "usage": {
            "instructions": [
                "1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Å—Å–∏—é: POST /emotime/session/start",
                "2. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ: POST /emotime/text –∏–ª–∏ /emotime/touch",
                "3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ: GET /emotime/status", 
                "4. –ü–æ–ª—É—á–∏—Ç–µ –∏–Ω—Å–∞–π—Ç—ã: GET /emotime/insights"
            ],
            "example_text_request": {
                "url": "/emotime/text",
                "method": "POST",
                "body": demo_scenarios[0]["text_data"]
            }
        }
    }


@emotime_router.get("/analytics", response_model=Dict[str, Any])
async def get_advanced_analytics(
    user_id: Optional[str] = None,
    time_range_hours: int = 24,
    include_predictions: bool = True
):
    """
    MIT-level Advanced Analytics Dashboard with ML insights.
    
    Provides world-class analytics from top AI research labs:
    - MIT: Real-time learning analytics & adaptation metrics
    - Stanford: Behavioral pattern analysis & predictive modeling  
    - OpenAI: Safety-first analytics & responsible AI metrics
    - DeepMind: Multi-agent emotional coordination analytics
    - Google Research: Scalable performance analytics
    """
    try:
        # Security: Use safe import with validation
        import os
        from .security.validators import safe_import_module
        
        # Secure import of analytics module
        analytics_path = os.path.join(os.path.dirname(__file__), 'analytics_standalone.py')
        analytics_module = safe_import_module('analytics_standalone', analytics_path)
        
        if not analytics_module:
            raise HTTPException(status_code=500, detail="Analytics module failed security validation")
        
        dashboard = analytics_module.get_standalone_analytics_dashboard()
        analytics_data = await dashboard.generate_comprehensive_analytics(
            user_id=user_id,
            time_range_hours=time_range_hours,
            include_predictions=include_predictions
        )
        
        return {
            "success": True,
            "data": analytics_data,
            "ai_lab_practices": [
                "MIT: Real-time learning & adaptation",
                "Stanford: Behavioral pattern recognition",
                "OpenAI: Safety-first analytics", 
                "DeepMind: Multi-agent coordination",
                "Google: Scalable performance analytics"
            ]
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analytics generation error: {str(e)}")


@emotime_router.get("/analytics/summary", response_model=Dict[str, Any]) 
async def get_analytics_summary():
    """
    Get analytics dashboard summary and capabilities.
    """
    try:
        # Security: Use safe import with validation
        import os
        from .security.validators import safe_import_module
        
        # Secure import of analytics module
        analytics_path = os.path.join(os.path.dirname(__file__), 'analytics_standalone.py')
        analytics_module = safe_import_module('analytics_standalone', analytics_path)
        
        if not analytics_module:
            raise HTTPException(status_code=500, detail="Analytics module failed security validation")
        
        dashboard = analytics_module.get_standalone_analytics_dashboard()
        summary = dashboard.get_dashboard_summary()
        
        return {
            "success": True,
            "data": summary,
            "description": "World-class emotional intelligence analytics powered by MIT ML insights"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analytics summary error: {str(e)}")