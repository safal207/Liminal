# ML-инфраструктура Resonance Liminal

## Архитектура

ML-инфраструктура Resonance Liminal представляет собой интегрированное решение для извлечения признаков, обучения моделей, предсказания аномалий и мониторинга всей системы.

### Компоненты системы

1. **Backend с ML-интеграцией**
   - Сбор данных о запросах и пользовательских сессиях
   - API для доступа к ML-метрикам
   - Интеграция с Redis и Prometheus

2. **Kenning ML-сервис**
   - Автоматизация ML-пайплайнов
   - Обучение и оптимизация моделей
   - Экспорт моделей в ONNX для инференса
   - REST API для предсказаний

3. **ML Feature Extractor**
   - Извлечение признаков из бэкенда
   - Сохранение признаков в Redis
   - Предобработка данных для ML-моделей

4. **ML Predictor**
   - Предсказание аномалий на основе извлеченных признаков
   - Объяснение предсказаний (XAI)
   - REST API для получения предсказаний и объяснений

5. **Auto-Retrainer**
   - Автоматическое переобучение моделей
   - Мониторинг дрейфа модели
   - Деплой новых моделей

6. **Мониторинг и визуализация**
   - Prometheus для сбора метрик
   - Grafana для визуализации
   - Алерты на основе ML-метрик

## Схема взаимодействия компонентов

```
Backend (8000) <-> Redis <-> Prometheus (9090)
     ^              ^             ^
     |              |             |
     v              v             v
Kenning (5000) <-> MinIO <-> ML Predictor (8002)
     ^              ^             ^
     |              |             |
     v              v             v
ML Feature Extractor   ML Auto-Retrainer
```

## Инструкции по запуску

### Запуск всей инфраструктуры

```bash
docker-compose -f docker-compose.ml.yml up -d
```

### Проверка работоспособности

1. Проверка предсказаний:
   ```
   curl http://localhost:8002/predict
   ```

2. Проверка здоровья Kenning:
   ```
   curl http://localhost:5000/health
   ```

3. Просмотр метрик в Prometheus:
   http://localhost:9090/graph

4. Настройка дашбордов в Grafana:
   http://localhost:3000 (admin/admin)

## ML-признаки, извлекаемые системой

| Признак | Описание | Источник |
|---------|----------|----------|
| requests_per_user | Частота запросов на пользователя | Backend API |
| burstiness_score | Коэффициент всплесков активности | Backend API |
| ip_entropy | Энтропия IP адресов | Backend API |
| channel_activity | Активность по каналам | WebSocket сервис |
| predicted_user_load | Предсказанная нагрузка | ML Predictor |
| login_intervals | Интервалы между логинами | Auth сервис |
| jwt_usage_patterns | Паттерны использования JWT | Auth сервис |

## Модели аномалий

В системе используются следующие модели аномалий:

1. **Isolation Forest** - для выявления аномалий в пользовательской активности
2. **One-Class SVM** - для выявления аномалий в паттернах запросов
3. **Автоэнкодеры** - для обнаружения аномалий в многомерных данных
4. **LSTM** - для обнаружения аномалий во временных рядах

## Интеграция с другими компонентами

- **Redis** - для хранения признаков и предсказаний
- **Prometheus** - для сбора метрик и алертинга
- **MinIO** - для хранения моделей и артефактов
- **Grafana** - для визуализации ML-метрик
- **XAI** - для объяснения предсказаний (SHAP, LIME)
- **Multi-LLM** - для интеллектуального анализа аномалий

## Советы по оптимизации

1. Установите переменные среды `OPENBLAS_NUM_THREADS=1` и `OMP_NUM_THREADS=1` для оптимизации ML-библиотек
2. Используйте модели в формате ONNX для быстрого инференса
3. Настройте TTL в Redis для хранения только актуальных данных
4. Настройте алерты в Prometheus для раннего обнаружения проблем
