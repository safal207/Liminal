"""
XAI (Explainable AI) Service –¥–ª—è Resonance Liminal.
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è SHAP, LIME –∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ ML-–º–æ–¥–µ–ª–µ–π.
"""

from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
from loguru import logger

# XAI –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    import shap
    from lime.lime_tabular import LimeTabularExplainer

    SHAP_AVAILABLE = True
    LIME_AVAILABLE = True
except ImportError:
    logger.warning("SHAP/LIME –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∏.")
    SHAP_AVAILABLE = False
    LIME_AVAILABLE = False

# Scikit-learn –¥–ª—è –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
try:
    from sklearn.ensemble import IsolationForest, RandomForestClassifier
    from sklearn.preprocessing import StandardScaler
    from sklearn.tree import DecisionTreeClassifier, export_text

    SKLEARN_AVAILABLE = True
except ImportError:
    logger.warning("Scikit-learn –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    SKLEARN_AVAILABLE = False


@dataclass
class ExplanationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏—è ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è."""

    prediction: Any
    confidence: float
    feature_importance: Dict[str, float]
    explanation_text: str
    shap_values: Optional[List[float]] = None
    lime_explanation: Optional[Dict[str, Any]] = None
    counterfactual: Optional[Dict[str, Any]] = None
    decision_path: Optional[List[str]] = None


class XAIService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º XAI –º–µ—Ç–æ–¥–æ–≤.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç SHAP, LIME, decision trees –∏ counterfactual explanations.
    """

    def __init__(self):
        self.explainers = {}  # –ö—ç—à explainer'–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.feature_names = {}  # –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á–µ–π –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        self.model_cache = {}  # –ö—ç—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.explanation_cache = {}  # –ö—ç—à –æ–±—ä—è—Å–Ω–µ–Ω–∏–π

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        self._init_demo_models()

        logger.info("XAI Service –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _init_demo_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è XAI."""
        if not SKLEARN_AVAILABLE:
            return

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ XAI
        try:
            # –ú–æ–¥–µ–ª—å –¥–ª—è anomaly detection
            self.anomaly_model = IsolationForest(
                contamination=0.1, random_state=42, n_estimators=100
            )

            # –ú–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            self.user_classifier = RandomForestClassifier(
                n_estimators=50, max_depth=10, random_state=42
            )

            # Decision Tree –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º—ã—Ö —Ä–µ—à–µ–Ω–∏–π
            self.decision_tree = DecisionTreeClassifier(max_depth=5, random_state=42)

            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ç–æ—Ä —Ñ–∏—á–µ–π
            self.scaler = StandardScaler()

            logger.info("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–µ–º–æ-–º–æ–¥–µ–ª–µ–π: {e}")

    def prepare_features(
        self, raw_features: Dict[str, Any], model_name: str
    ) -> Tuple[np.ndarray, List[str]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–∏—á–∏ –¥–ª—è ML-–º–æ–¥–µ–ª–∏.

        Args:
            raw_features: –°—ã—Ä—ã–µ —Ñ–∏—á–∏
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Returns:
            Tuple[prepared_features, feature_names]
        """
        if model_name == "anomaly_detection":
            feature_names = [
                "messages_per_minute",
                "avg_message_size",
                "error_rate",
                "rate_limit_violations",
                "channels_count",
                "connection_duration",
                "burstiness_score",
                "ip_entropy",
            ]
        elif model_name == "user_behavior":
            feature_names = [
                "avg_messages_per_session",
                "avg_session_duration",
                "unique_channels",
                "avg_error_rate",
                "total_sessions",
            ]
        else:
            # –û–±—â–∏–µ —Ñ–∏—á–∏
            feature_names = list(raw_features.keys())

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ–∏—á–µ–π
        features = []
        for name in feature_names:
            value = raw_features.get(name, 0.0)
            if isinstance(value, (int, float)):
                features.append(float(value))
            else:
                features.append(0.0)  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –Ω–µ—á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

        self.feature_names[model_name] = feature_names
        return np.array(features).reshape(1, -1), feature_names

    def explain_with_shap(
        self,
        model: Any,
        features: np.ndarray,
        feature_names: List[str],
        model_name: str,
    ) -> Dict[str, Any]:
        """
        –û–±—ä—è—Å–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é SHAP.

        Args:
            model: ML-–º–æ–¥–µ–ª—å
            features: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
            feature_names: –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á–µ–π
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

        Returns:
            SHAP –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        if not SHAP_AVAILABLE:
            return {"error": "SHAP –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"}

        try:
            # –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º SHAP explainer
            if model_name not in self.explainers:
                if hasattr(model, "predict_proba"):
                    # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
                    self.explainers[model_name] = shap.TreeExplainer(model)
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π
                    self.explainers[model_name] = shap.Explainer(model)

            explainer = self.explainers[model_name]

            # –í—ã—á–∏—Å–ª—è–µ–º SHAP values
            shap_values = explainer.shap_values(features)

            # –ï—Å–ª–∏ —ç—Ç–æ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å
            if isinstance(shap_values, list):
                shap_values = shap_values[0]

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            feature_importance = {}
            if len(shap_values.shape) > 1:
                shap_values = shap_values[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –æ–±—Ä–∞–∑–µ—Ü

            for i, name in enumerate(feature_names):
                if i < len(shap_values):
                    feature_importance[name] = float(shap_values[i])

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_importance = dict(
                sorted(
                    feature_importance.items(), key=lambda x: abs(x[1]), reverse=True
                )
            )

            return {
                "shap_values": shap_values.tolist(),
                "feature_importance": sorted_importance,
                "explanation": self._generate_shap_explanation(sorted_importance),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ SHAP –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
            return {"error": str(e)}

    def explain_with_lime(
        self,
        model: Any,
        features: np.ndarray,
        feature_names: List[str],
        training_data: Optional[np.ndarray] = None,
    ) -> Dict[str, Any]:
        """
        –û–±—ä—è—Å–Ω—è–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é LIME.

        Args:
            model: ML-–º–æ–¥–µ–ª—å
            features: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
            feature_names: –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á–µ–π
            training_data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LIME

        Returns:
            LIME –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        if not LIME_AVAILABLE:
            return {"error": "LIME –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"}

        try:
            # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
            if training_data is None:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è LIME
                training_data = np.random.normal(
                    loc=features.mean(axis=0),
                    scale=features.std(axis=0) + 0.1,
                    size=(100, features.shape[1]),
                )

            # –°–æ–∑–¥–∞–µ–º LIME explainer
            explainer = LimeTabularExplainer(
                training_data,
                feature_names=feature_names,
                mode=(
                    "classification"
                    if hasattr(model, "predict_proba")
                    else "regression"
                ),
            )

            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            explanation = explainer.explain_instance(
                features[0],
                (
                    model.predict_proba
                    if hasattr(model, "predict_proba")
                    else model.predict
                ),
                num_features=len(feature_names),
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π
            feature_importance = {}
            for feature_idx, importance in explanation.as_list():
                if isinstance(feature_idx, str):
                    feature_importance[feature_idx] = importance
                else:
                    feature_importance[feature_names[feature_idx]] = importance

            return {
                "feature_importance": feature_importance,
                "explanation": self._generate_lime_explanation(feature_importance),
                "lime_html": (
                    explanation.as_html() if hasattr(explanation, "as_html") else None
                ),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ LIME –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
            return {"error": str(e)}

    def explain_decision_tree(
        self, model: Any, features: np.ndarray, feature_names: List[str]
    ) -> Dict[str, Any]:
        """
        –û–±—ä—è—Å–Ω—è–µ—Ç —Ä–µ—à–µ–Ω–∏–µ decision tree –º–æ–¥–µ–ª–∏.

        Args:
            model: Decision tree –º–æ–¥–µ–ª—å
            features: –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
            feature_names: –ù–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á–µ–π

        Returns:
            –û–±—ä—è—Å–Ω–µ–Ω–∏–µ decision tree
        """
        if not SKLEARN_AVAILABLE:
            return {"error": "Scikit-learn –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω"}

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å —Ä–µ—à–µ–Ω–∏—è
            decision_path = model.decision_path(features)
            leaf_id = model.apply(features)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∞–≤–∏–ª–∞
            tree_rules = export_text(model, feature_names=feature_names)

            # –°–æ–∑–¥–∞–µ–º –ø–æ—à–∞–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            explanation_steps = []

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —É–∑–ª–æ–≤ –≤ –ø—É—Ç–∏ —Ä–µ—à–µ–Ω–∏—è
            feature_indices = decision_path.indices[
                decision_path.indptr[0] : decision_path.indptr[1]
            ]

            for node_id in feature_indices:
                if node_id != leaf_id[0]:  # –ù–µ –≤–∫–ª—é—á–∞–µ–º –ª–∏—Å—Ç–æ–≤–æ–π —É–∑–µ–ª
                    feature_idx = model.tree_.feature[node_id]
                    threshold = model.tree_.threshold[node_id]

                    if feature_idx >= 0:  # –ù–µ –ª–∏—Å—Ç–æ–≤–æ–π —É–∑–µ–ª
                        feature_name = feature_names[feature_idx]
                        feature_value = features[0][feature_idx]

                        if feature_value <= threshold:
                            condition = f"{feature_name} <= {threshold:.3f}"
                            direction = "left"
                        else:
                            condition = f"{feature_name} > {threshold:.3f}"
                            direction = "right"

                        explanation_steps.append(
                            {
                                "condition": condition,
                                "feature": feature_name,
                                "value": float(feature_value),
                                "threshold": float(threshold),
                                "direction": direction,
                            }
                        )

            return {
                "decision_path": explanation_steps,
                "tree_rules": tree_rules,
                "explanation": self._generate_tree_explanation(explanation_steps),
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è decision tree: {e}")
            return {"error": str(e)}

    def generate_counterfactual(
        self, features: Dict[str, Any], model_name: str, target_outcome: Any = None
    ) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç counterfactual –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ.
        "–ß—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥—Ä—É–≥–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç?"

        Args:
            features: –ò—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∏—á–∏
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            target_outcome: –ñ–µ–ª–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç

        Returns:
            Counterfactual –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        """
        try:
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è counterfactual
            counterfactual_features = features.copy()
            suggestions = []

            if model_name == "anomaly_detection":
                # –î–ª—è anomaly detection –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Å–Ω–∏–∑–∏—Ç—å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                if features.get("messages_per_minute", 0) > 20:
                    counterfactual_features["messages_per_minute"] = 15
                    suggestions.append("–°–Ω–∏–∑–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ 15/–º–∏–Ω")

                if features.get("error_rate", 0) > 0.1:
                    counterfactual_features["error_rate"] = 0.05
                    suggestions.append("–£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (—Å–Ω–∏–∑–∏—Ç—å –æ—à–∏–±–∫–∏)")

                if features.get("rate_limit_violations", 0) > 0:
                    counterfactual_features["rate_limit_violations"] = 0
                    suggestions.append("–ò–∑–±–µ–≥–∞—Ç—å –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤")

            elif model_name == "user_behavior":
                # –î–ª—è user behavior –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                if features.get("avg_session_duration", 0) < 300:  # –ú–µ–Ω—å—à–µ 5 –º–∏–Ω—É—Ç
                    counterfactual_features["avg_session_duration"] = 600
                    suggestions.append("–£–≤–µ–ª–∏—á–∏—Ç—å –≤—Ä–µ–º—è —Å–µ—Å—Å–∏–∏ –¥–æ 10+ –º–∏–Ω—É—Ç")

                if features.get("unique_channels", 0) > 10:
                    counterfactual_features["unique_channels"] = 5
                    suggestions.append("–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ –º–µ–Ω—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –∫–∞–Ω–∞–ª–æ–≤")

            return {
                "original_features": features,
                "counterfactual_features": counterfactual_features,
                "suggestions": suggestions,
                "explanation": f"–î–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: {'; '.join(suggestions)}",
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ counterfactual: {e}")
            return {"error": str(e)}

    def _generate_shap_explanation(self, feature_importance: Dict[str, float]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ SHAP —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        if not feature_importance:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"

        top_features = list(feature_importance.items())[:3]

        explanation = "–ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n"
        for i, (feature, importance) in enumerate(top_features, 1):
            direction = "—É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç" if importance > 0 else "—É–º–µ–Ω—å—à–∞–µ—Ç"
            explanation += (
                f"{i}. {feature}: {direction} –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ {abs(importance):.3f}\n"
            )

        return explanation

    def _generate_lime_explanation(self, feature_importance: Dict[str, float]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ LIME —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        if not feature_importance:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è"

        sorted_features = sorted(
            feature_importance.items(), key=lambda x: abs(x[1]), reverse=True
        )[:3]

        explanation = "–õ–æ–∫–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:\n"
        for i, (feature, importance) in enumerate(sorted_features, 1):
            direction = (
                "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç" if importance > 0 else "–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ –≤–ª–∏—è–µ—Ç"
            )
            explanation += f"{i}. {feature}: {direction} (–≤–µ—Å: {importance:.3f})\n"

        return explanation

    def _generate_tree_explanation(self, decision_path: List[Dict[str, Any]]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ decision tree."""
        if not decision_path:
            return "–ü—Ä—è–º–æ–µ —Ä–µ—à–µ–Ω–∏–µ –±–µ–∑ —É—Å–ª–æ–≤–∏–π"

        explanation = "–ü—É—Ç—å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è:\n"
        for i, step in enumerate(decision_path, 1):
            explanation += f"{i}. {step['condition']}\n"

        explanation += (
            f"\n–ò—Ç–æ–≥–æ: —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(decision_path)} —É—Å–ª–æ–≤–∏–π"
        )
        return explanation

    async def explain_prediction(
        self,
        model_name: str,
        features: Dict[str, Any],
        prediction: Any,
        confidence: float = 0.0,
        use_cache: bool = True,
    ) -> ExplanationResult:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            features: –§–∏—á–∏ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
            prediction: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à –æ–±—ä—è—Å–Ω–µ–Ω–∏–π

        Returns:
            –ü–æ–ª–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cache_key = f"{model_name}:{hash(str(sorted(features.items())))}"
        if use_cache and cache_key in self.explanation_cache:
            return self.explanation_cache[cache_key]

        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏—á–∏
            prepared_features, feature_names = self.prepare_features(
                features, model_name
            )

            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
            model = self._get_model_for_explanation(model_name)
            if model is None:
                return ExplanationResult(
                    prediction=prediction,
                    confidence=confidence,
                    feature_importance={},
                    explanation_text="–ú–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è",
                )

            # –°–æ–±–∏—Ä–∞–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
            explanations = {}

            # SHAP –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            shap_result = self.explain_with_shap(
                model, prepared_features, feature_names, model_name
            )
            if "error" not in shap_result:
                explanations["shap"] = shap_result

            # LIME –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            lime_result = self.explain_with_lime(
                model, prepared_features, feature_names
            )
            if "error" not in lime_result:
                explanations["lime"] = lime_result

            # Decision tree –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
            if hasattr(model, "tree_"):
                tree_result = self.explain_decision_tree(
                    model, prepared_features, feature_names
                )
                if "error" not in tree_result:
                    explanations["tree"] = tree_result

            # Counterfactual –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            counterfactual = self.generate_counterfactual(features, model_name)

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å —Ñ–∏—á–µ–π –∏–∑ —Ä–∞–∑–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
            combined_importance = {}
            if "shap" in explanations:
                combined_importance.update(explanations["shap"]["feature_importance"])
            elif "lime" in explanations:
                combined_importance.update(explanations["lime"]["feature_importance"])

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
            explanation_text = self._generate_combined_explanation(
                prediction, confidence, explanations, counterfactual
            )

            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = ExplanationResult(
                prediction=prediction,
                confidence=confidence,
                feature_importance=combined_importance,
                explanation_text=explanation_text,
                shap_values=explanations.get("shap", {}).get("shap_values"),
                lime_explanation=explanations.get("lime"),
                counterfactual=counterfactual,
                decision_path=explanations.get("tree", {}).get("decision_path"),
            )

            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if use_cache:
                self.explanation_cache[cache_key] = result

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
                if len(self.explanation_cache) > 1000:
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
                    old_keys = list(self.explanation_cache.keys())[:100]
                    for key in old_keys:
                        del self.explanation_cache[key]

            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return ExplanationResult(
                prediction=prediction,
                confidence=confidence,
                feature_importance={},
                explanation_text=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {str(e)}",
            )

    def _get_model_for_explanation(self, model_name: str) -> Any:
        """–ü–æ–ª—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è."""
        if model_name == "anomaly_detection":
            return getattr(self, "anomaly_model", None)
        elif model_name == "user_behavior":
            return getattr(self, "user_classifier", None)
        else:
            return getattr(self, "decision_tree", None)

    def _generate_combined_explanation(
        self,
        prediction: Any,
        confidence: float,
        explanations: Dict[str, Any],
        counterfactual: Dict[str, Any],
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ."""
        text = f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})\n\n"

        # –î–æ–±–∞–≤–ª—è–µ–º SHAP –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        if "shap" in explanations:
            text += "üîç SHAP Analysis:\n"
            text += explanations["shap"]["explanation"] + "\n"

        # –î–æ–±–∞–≤–ª—è–µ–º LIME –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        if "lime" in explanations:
            text += "üéØ LIME Analysis:\n"
            text += explanations["lime"]["explanation"] + "\n"

        # –î–æ–±–∞–≤–ª—è–µ–º decision tree –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
        if "tree" in explanations:
            text += "üå≥ Decision Tree Path:\n"
            text += explanations["tree"]["explanation"] + "\n"

        # –î–æ–±–∞–≤–ª—è–µ–º counterfactual
        if "error" not in counterfactual and counterfactual.get("suggestions"):
            text += "üí° Recommendations:\n"
            text += counterfactual["explanation"] + "\n"

        return text


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä XAI —Å–µ—Ä–≤–∏—Å–∞
xai_service = XAIService()
