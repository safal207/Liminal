#!/usr/bin/env python3
"""
üß†üß≠ BRAIN COMPASS INTERACTIVE DEMO

–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–µ–º–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –º–æ–∑–≥–æ–≤–æ–≥–æ –∫–æ–º–ø–∞—Å–∞
–≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö –æ—Å—Ü–∏–ª–ª—è—Ü–∏–π.
"""

import asyncio
import time
import math
from datetime import datetime
from typing import Dict, List, Any

try:
    from retrosplenial_gateway import RetrosplenialGateway, NavigationEvent, NavigationContext
    SYSTEM_AVAILABLE = True
except ImportError:
    SYSTEM_AVAILABLE = False


class BrainCompassDemo:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –¥–µ–º–æ –º–æ–∑–≥–æ–≤–æ–≥–æ –∫–æ–º–ø–∞—Å–∞."""
    
    def __init__(self):
        if SYSTEM_AVAILABLE:
            self.gateway = RetrosplenialGateway()
            self._setup_demo_context()
        
        self.demo_events = self._create_demo_events()
        self.visualization_active = False
    
    def _setup_demo_context(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–µ–º–æ."""
        context = NavigationContext(
            current_state="interactive_demo",
            target_state="showcase_neural_capabilities",
            emotional_context={"curiosity": 0.9, "excitement": 0.8, "focus": 0.7}
        )
        self.gateway.set_navigation_context(context)
    
    def _create_demo_events(self) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–µ–º–æ —Å–æ–±—ã—Ç–∏–π."""
        return [
            {
                "name": "Creative Inspiration",
                "description": "Sudden creative inspiration for a new project",
                "emotional_valence": 0.8,
                "urgency": 0.4,
                "expected_direction": "east_create",
                "demo_notes": "Should trigger EAST (Create) with high-gamma binding"
            },
            {
                "name": "Learning Challenge",
                "description": "Encountering a new complex concept in neuroscience",
                "emotional_valence": 0.3,
                "urgency": 0.6,
                "expected_direction": "north_evolve",
                "demo_notes": "Should trigger NORTH (Evolve) with theta enhancement"
            },
            {
                "name": "Emotional Overwhelm",
                "description": "Feeling emotional overwhelm from multiple tasks",
                "emotional_valence": -0.6,
                "urgency": 0.9,
                "expected_direction": "south_instinct",
                "demo_notes": "Should trigger SOUTH (Instinct) with survival focus"
            },
            {
                "name": "Deep Reflection",
                "description": "Reflecting on the meaning of life and my values",
                "emotional_valence": 0.1,
                "urgency": 0.2,
                "expected_direction": "west_reflect", 
                "demo_notes": "Should trigger WEST (Reflect) with contemplative theta"
            },
            {
                "name": "Breakthrough Discovery",
                "description": "Discovering fundamental connections between ideas",
                "emotional_valence": 0.9,
                "urgency": 0.3,
                "expected_direction": "north_evolve",
                "demo_notes": "Should trigger NORTH (Evolve) with strong coupling"
            }
        ]
    
    async def run_interactive_demo(self):
        """–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–µ–º–æ."""
        
        print("BRAIN COMPASS INTERACTIVE DEMO")
        print("="*50)
        print()
        print("This demo showcases:")
        print("* Real-time theta oscillations (4-8Hz)")
        print("* Gamma synchrony memory binding (30-100Hz)")
        print("* Cross-frequency coupling")
        print("* Semantic directional navigation")
        print()
        
        if not SYSTEM_AVAILABLE:
            print("[WARNING] RGL system not available - running conceptual demo")
            await self._run_conceptual_demo()
            return
        
        print("Choose demo mode:")
        print("1. [AUTO] Automated showcase")
        print("2. [MONITOR] Real-time oscillation monitoring")
        print("3. [TEST] Interactive event testing")
        print()
        
        # –í –¥–µ–º–æ —Ä–µ–∂–∏–º–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ
        await self._run_automated_showcase()
        await asyncio.sleep(1)
        await self._run_oscillation_monitoring()
        await asyncio.sleep(1)  
        await self._run_interactive_testing()
    
    async def _run_automated_showcase(self):
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π."""
        
        print("\n[AUTO] AUTOMATED SHOWCASE")
        print("-"*30)
        print("Processing diverse events to show neural navigation...")
        print()
        
        for i, event_data in enumerate(self.demo_events, 1):
            print(f"[{i}/{len(self.demo_events)}] {event_data['name']}")
            print(f"Description: {event_data['description']}")
            print(f"Expected: {event_data['expected_direction']} direction")
            print(f"Demo Note: {event_data['demo_notes']}")
            print()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
            event = NavigationEvent(
                event_id=f"demo_{i}_{int(time.time())}",
                event_type="demo_event",
                content=event_data['description'],
                timestamp=datetime.now(),
                source_layer="interactive_demo",
                emotional_valence=event_data['emotional_valence'],
                urgency_level=event_data['urgency']
            )
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è
            direction = await self.gateway.process_navigation_event(event)
            analytics = self.gateway.get_navigation_analytics()
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._display_navigation_result(direction, analytics, event_data)
            
            await asyncio.sleep(1)
        
        print("[OK] Automated showcase completed!")
    
    async def _run_oscillation_monitoring(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö –æ—Å—Ü–∏–ª–ª—è—Ü–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏."""
        
        print("\n[MONITOR] REAL-TIME OSCILLATION MONITORING")
        print("-"*40)
        print("Monitoring theta and gamma oscillations for 10 seconds...")
        print("Watch how oscillations evolve and couple together!")
        print()
        
        monitoring_duration = 10
        start_time = time.time()
        
        while time.time() - start_time < monitoring_duration:
            analytics = self.gateway.get_navigation_analytics()
            
            theta = analytics['theta_oscillations']
            gamma = analytics['gamma_synchrony']
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—É—â–∏—Ö –æ—Å—Ü–∏–ª–ª—è—Ü–∏–π
            elapsed = time.time() - start_time
            print(f"[{elapsed:.1f}s] Theta: {theta['theta_type']} @ {theta['current_frequency']:.1f}Hz (power: {theta['current_power']:.2f}) | "
                  f"Gamma: {gamma['gamma_band']} @ {gamma['current_frequency']:.1f}Hz (sync: {gamma['synchrony_strength']:.2f}) | "
                  f"Coupling: {gamma['gamma_theta_coupling']:.3f}")
            
            # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å–∏–ª—ã —Å–≤—è–∑–∏
            coupling = gamma['gamma_theta_coupling']
            if coupling > 0.7:
                print("         [STRONG] STRONG COUPLING!")
            elif coupling > 0.4:
                print("         [OK] MODERATE COUPLING")
            else:
                print("         [WEAK] WEAK COUPLING")
            
            await asyncio.sleep(1)
        
        print("\n[MONITOR] Oscillation monitoring completed!")
    
    async def _run_interactive_testing(self):
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π."""
        
        print("\n[TEST] INTERACTIVE EVENT TESTING")
        print("-"*35)
        print("Testing how different types of events affect neural navigation...")
        print()
        
        test_scenarios = [
            {
                "category": "SPATIAL PROCESSING",
                "description": "Navigate through complex 3D coordinate system",
                "expected_theta": "fast_spatial (8Hz)",
                "expected_direction": "east_create"
            },
            {
                "category": "EMOTIONAL PROCESSING", 
                "description": "Process deep emotional memories and feelings",
                "expected_theta": "slow_conceptual (3Hz)",
                "expected_direction": "west_reflect"
            },
            {
                "category": "LEARNING PROCESS",
                "description": "Master advanced quantum mechanics concepts",
                "expected_theta": "adaptive_human (4Hz)",
                "expected_direction": "north_evolve"
            },
            {
                "category": "CRISIS RESPONSE",
                "description": "Handle immediate safety threat and danger",
                "expected_theta": "adaptive_human (4Hz)",
                "expected_direction": "south_instinct"
            }
        ]
        
        for scenario in test_scenarios:
            print(f"[TEST] Testing: {scenario['category']}")
            print(f"Event: {scenario['description']}")
            print(f"Expected Theta: {scenario['expected_theta']}")
            print(f"Expected Direction: {scenario['expected_direction']}")
            print()
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è
            event = NavigationEvent(
                event_id=f"test_{scenario['category'].lower()}_{int(time.time())}",
                event_type=scenario['category'].lower().replace(' ', '_'),
                content=scenario['description'],
                timestamp=datetime.now(),
                source_layer="interactive_testing",
                emotional_valence=0.5,
                urgency_level=0.5 if 'CRISIS' not in scenario['category'] else 0.9
            )
            
            direction = await self.gateway.process_navigation_event(event)
            analytics = self.gateway.get_navigation_analytics()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            theta_info = analytics['theta_oscillations']
            actual_direction = direction.primary_direction.value
            
            print(f"[RESULTS]:")
            print(f"   Actual Theta: {theta_info['theta_type']} @ {theta_info['current_frequency']:.1f}Hz")
            print(f"   Actual Direction: {actual_direction}")
            print(f"   Direction Strength: {direction.strength:.2f}")
            print(f"   Gamma Coupling: {analytics['gamma_synchrony']['gamma_theta_coupling']:.3f}")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            if scenario['expected_direction'] in actual_direction:
                print(f"   [OK] Direction prediction CORRECT!")
            else:
                print(f"   [NOTE] Direction unexpected (but system is adaptive)")
            
            print()
            await asyncio.sleep(1)
        
        print("[TEST] Interactive testing completed!")
    
    def _display_navigation_result(self, direction, analytics, event_data):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏."""
        
        theta = analytics['theta_oscillations']
        gamma = analytics['gamma_synchrony']
        
        print(f"[BRAIN] NEURAL PROCESSING RESULT:")
        print(f"   Direction: {direction.primary_direction.value} (strength: {direction.strength:.2f})")
        print(f"   Confidence: {direction.confidence:.2f}")
        print(f"   Theta: {theta['theta_type']} @ {theta['current_frequency']:.1f}Hz")
        print(f"   Gamma: {gamma['gamma_band']} @ {gamma['current_frequency']:.1f}Hz")
        print(f"   Coupling: {gamma['gamma_theta_coupling']:.3f}")
        print(f"   Memory Anchors: {analytics['memory_anchors']}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        if event_data['expected_direction'] in direction.primary_direction.value:
            print(f"   [OK] Expected direction achieved!")
        else:
            print(f"   [ADAPT] Adaptive direction (system responding to context)")
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—ã –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        if direction.strength > 2.0:
            print(f"   [BOOST] EXCEPTIONAL strength - neural enhancement active!")
        elif direction.strength > 1.5:
            print(f"   [STRONG] STRONG direction - good neural coordination")
        elif direction.strength > 1.0:
            print(f"   [OK] SOLID direction - moderate enhancement")
        
        print()
    
    async def _run_conceptual_demo(self):
        """–ö–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ–µ –¥–µ–º–æ –±–µ–∑ RGL —Å–∏—Å—Ç–µ–º—ã."""
        
        print("[CONCEPT] CONCEPTUAL DEMONSTRATION")
        print("Showing how Brain Compass would process events...")
        print()
        
        for event_data in self.demo_events:
            print(f"[EVENT] Event: {event_data['name']}")
            print(f"   Description: {event_data['description']}")
            print(f"   Expected Direction: {event_data['expected_direction']}")
            print(f"   Demo Notes: {event_data['demo_notes']}")
            
            # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            print(f"   [BRAIN] Simulated Processing:")
            print(f"      -> Direction: {event_data['expected_direction']}")
            print(f"      -> Theta frequency adaptation based on content")
            print(f"      -> Gamma synchrony for memory binding")
            print(f"      -> Cross-frequency coupling enhancement")
            print()
            
            await asyncio.sleep(0.5)
        
        print("[COMPLETE] Conceptual demo complete! Install RGL for full experience.")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ."""
    demo = BrainCompassDemo()
    await demo.run_interactive_demo()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n[STOP] Demo interrupted")
    except Exception as e:
        print(f"\nDemo error: {e}")
        import traceback
        traceback.print_exc()