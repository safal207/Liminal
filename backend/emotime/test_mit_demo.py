"""
üöÄüß† MIT Emotime Advanced Demo ‚Äî –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è MIT-level –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –ê–¥–∞–ø—Ç–∏–≤–Ω—É—é –∫–∞–ª–∏–±—Ä–æ–≤–∫—É —Å —ç–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
- –û–±—É—á–µ–Ω–∏–µ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É
- Multi-modal sensor fusion (–≥–¥–µ –¥–æ—Å—Ç—É–ø–Ω–æ)
"""

import asyncio
from datetime import datetime, timedelta
import random

from .core import EmotimeEngine
from .sensors import SensorData, SensorType, TextData, TouchData, AudioData
from .modes import ModeType
from .utils import safe_logger


async def mit_emotional_journey_with_learning():
    """MIT –¥–µ–º–æ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º."""
    safe_logger.info("=== MIT EMOTIME ADVANCED DEMO ===")
    
    # –°–æ–∑–¥–∞–µ–º MIT-enhanced –¥–≤–∏–∂–æ–∫
    engine = EmotimeEngine(
        user_id="mit_demo_user",
        session_id="mit_advanced_session",
        update_interval=0.5,  # –ë—ã—Å—Ç—Ä–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è –¥–µ–º–æ
        enable_neo4j=False,
        enable_ml=True  # –í–∫–ª—é—á–∞–µ–º –≤—Å–µ MIT –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    )
    
    try:
        await engine.start()
        safe_logger.info("MIT Engine started with advanced capabilities")
        
        # –§–∞–∑–∞ 1: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
        safe_logger.info("Phase 1: Learning Phase with Feedback...")
        
        training_scenarios = [
            # –°—Ü–µ–Ω–∞—Ä–∏–∏ —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏
            {
                "text": "I'm feeling completely zen and peaceful today",
                "touch": {"pressure": 0.2, "duration": 3.0, "frequency": 1.0, "pattern": "gentle"},
                "actual_emotion": "calm",
                "context": {"time_of_day": 0.3, "session_length": 0.2}
            },
            {
                "text": "URGENT DEADLINE! Need to finish this NOW!!!",
                "touch": {"pressure": 0.9, "duration": 0.1, "frequency": 10.0, "pattern": "rapid_taps"},
                "actual_emotion": "stress",
                "context": {"time_of_day": 0.8, "session_length": 0.9}
            },
            {
                "text": "YES! I finally solved this problem! Amazing!",
                "touch": {"pressure": 0.7, "duration": 2.0, "frequency": 5.0, "pattern": "rhythmic"},
                "actual_emotion": "joy",
                "context": {"time_of_day": 0.6, "session_length": 0.5}
            },
            {
                "text": "Need to focus deeply on this complex task",
                "touch": {"pressure": 0.5, "duration": 4.0, "frequency": 2.0, "pattern": "hold"},
                "actual_emotion": "focus",
                "context": {"time_of_day": 0.5, "session_length": 0.7}
            },
            {
                "text": "Hmm, let me think about this philosophical question",
                "touch": {"pressure": 0.3, "duration": 5.0, "frequency": 0.5, "pattern": "gentle"},
                "actual_emotion": "contemplation",
                "context": {"time_of_day": 0.2, "session_length": 0.3}
            }
        ]
        
        # –û–±—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º—É
        for i, scenario in enumerate(training_scenarios * 2):  # –ü–æ–≤—Ç–æ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–≤–∞–∂–¥—ã
            safe_logger.info(f"Training scenario {i+1}: {scenario['actual_emotion']}")
            
            # –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            text_data = TextData(
                text=scenario["text"],
                word_count=len(scenario["text"].split()),
                char_count=len(scenario["text"]),
                typing_speed=random.uniform(50, 150),
                pause_duration=random.uniform(0.5, 3.0)
            )
            
            # –¢–∞–∫—Ç–∏–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            touch_data = TouchData(
                pressure=scenario["touch"]["pressure"],
                duration=scenario["touch"]["duration"],
                frequency=scenario["touch"]["frequency"],
                pattern=scenario["touch"]["pattern"]
            )
            
            # –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ (—Å–∏–º—É–ª–∏—Ä—É–µ–º)
            audio_data = AudioData(
                pitch_mean=0.6 + random.uniform(-0.2, 0.2),
                pitch_variance=0.3 + random.uniform(-0.1, 0.1),
                speech_rate=120 + random.uniform(-30, 30),
                volume_level=0.7 + random.uniform(-0.2, 0.2),
                pause_ratio=0.15 + random.uniform(-0.05, 0.05),
                emotion_markers=[scenario["actual_emotion"]]
            )
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
            sensor_data_batch = [
                SensorData(
                    sensor_type=SensorType.TEXT,
                    timestamp=datetime.now(),
                    raw_data=text_data,
                    metadata=scenario["context"]
                ),
                SensorData(
                    sensor_type=SensorType.TOUCH,
                    timestamp=datetime.now(),
                    raw_data=touch_data,
                    metadata=scenario["context"]
                ),
                SensorData(
                    sensor_type=SensorType.AUDIO,
                    timestamp=datetime.now(),
                    raw_data=audio_data,
                    metadata=scenario["context"]
                )
            ]
            
            for data in sensor_data_batch:
                await engine.process_sensor_data(data)
            
            # –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            await asyncio.sleep(1)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –æ–±—É—á–∞–µ–º –Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            current_state = await engine.get_current_state()
            if current_state:
                predicted = current_state.mode.name.lower()
                actual = scenario["actual_emotion"]
                confidence = current_state.confidence
                
                safe_logger.info(
                    f"  Predicted: {predicted} (conf: {confidence:.2f}) | "
                    f"Actual: {actual} | "
                    f"Correct: {predicted == actual or predicted in actual}"
                )
                
                # –û–±—É—á–µ–Ω–∏–µ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é
                await engine.learn_from_feedback(actual, scenario["context"])
        
        # –§–∞–∑–∞ 2: –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        safe_logger.info("\nPhase 2: Calibration Analysis...")
        
        insights = await engine.get_emotional_insights()
        
        if "adaptive_calibration" in insights:
            calibration = insights["adaptive_calibration"]
            safe_logger.info(f"Current Performance: {calibration['current_performance']:.3f}")
            safe_logger.info(f"Baseline Performance: {calibration['baseline_performance']:.3f}")
            safe_logger.info(f"Total Feedback: {calibration['total_feedback']}")
            safe_logger.info(f"Calibration Events: {calibration['calibration_events']}")
            safe_logger.info(f"Optimizer Generation: {calibration['optimizer_generation']}")
        
        if "calibrated_thresholds" in insights:
            thresholds = insights["calibrated_thresholds"]
            safe_logger.info(f"Calibration Status: {thresholds['calibration_status']}")
            if thresholds["calibration_status"] == "optimized":
                safe_logger.info(f"Performance Score: {thresholds['performance_score']:.3f}")
                safe_logger.info(f"Evolution Generation: {thresholds['generation']}")
        
        # –§–∞–∑–∞ 3: –¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        safe_logger.info("\nPhase 3: Performance Test...")
        
        test_scenarios = [
            {"text": "I feel so relaxed and at peace", "expected": "calm"},
            {"text": "This is URGENT and CRITICAL!", "expected": "stress"},
            {"text": "I'm so excited about this breakthrough!", "expected": "joy"},
            {"text": "I need to concentrate on this problem", "expected": "focus"}
        ]
        
        correct_predictions = 0
        total_predictions = len(test_scenarios)
        
        for scenario in test_scenarios:
            text_data = TextData(
                text=scenario["text"],
                word_count=len(scenario["text"].split()),
                char_count=len(scenario["text"])
            )
            
            sensor_data = SensorData(
                sensor_type=SensorType.TEXT,
                timestamp=datetime.now(),
                raw_data=text_data,
                metadata={}
            )
            
            await engine.process_sensor_data(sensor_data)
            await asyncio.sleep(0.6)
            
            current_state = await engine.get_current_state()
            if current_state:
                predicted = current_state.mode.name.lower()
                expected = scenario["expected"]
                confidence = current_state.confidence
                
                is_correct = (predicted == expected or 
                             predicted in expected or 
                             expected in predicted)
                
                if is_correct:
                    correct_predictions += 1
                
                safe_logger.info(
                    f"Test: '{scenario['text'][:40]}...' | "
                    f"Predicted: {predicted} | Expected: {expected} | "
                    f"Confidence: {confidence:.2f} | {'‚úì' if is_correct else '‚úó'}"
                )
        
        final_accuracy = correct_predictions / total_predictions
        safe_logger.info(f"\nFinal Test Accuracy: {final_accuracy:.1%} ({correct_predictions}/{total_predictions})")
        
        # –§–∞–∑–∞ 4: Advanced Analytics
        safe_logger.info("\nPhase 4: Advanced MIT Analytics...")
        
        final_insights = await engine.get_emotional_insights()
        
        safe_logger.info("=== MIT ANALYTICS SUMMARY ===")
        safe_logger.info(f"Current State: {final_insights['current_state']['status']}")
        
        if final_insights['current_state']['status'] == 'active':
            current = final_insights['current_state']
            safe_logger.info(f"Final Mode: {current['mode']['name']}")
            safe_logger.info(f"ML Enhanced: {current['ml_enhanced']}")
            safe_logger.info(f"Confidence: {current['confidence']:.3f}")
            safe_logger.info(f"Trace Points: {current['trace_points']}")
        
        # ML Analytics
        if "ml_analytics" in final_insights:
            ml_data = final_insights["ml_analytics"]
            safe_logger.info(f"ML Algorithm: {ml_data.get('current_algorithm', 'N/A')}")
            safe_logger.info(f"Training Samples: {ml_data.get('training_samples', 0)}")
            safe_logger.info(f"ML Available: {ml_data.get('ml_available', False)}")
        
        # Deep Learning
        if "deep_learning" in final_insights:
            dl_data = final_insights["deep_learning"]
            safe_logger.info(f"Temporal Buffer: {dl_data.get('temporal_buffer_size', 0)}")
            safe_logger.info(f"Attention Mechanisms: {len(dl_data.get('attention_mechanisms', {}).get('last_weights', []))}")
        
        # Triggers adaptive learning update
        await engine.trigger_adaptive_learning()
        
        safe_logger.info("\n=== MIT EMOTIME DEMO COMPLETED ===")
        safe_logger.info("Advanced emotional intelligence with adaptive learning demonstrated!")
        
    except Exception as e:
        safe_logger.error(f"MIT Demo error: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        await engine.stop()
        safe_logger.info("MIT Engine stopped")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è MIT –¥–µ–º–æ."""
    try:
        await mit_emotional_journey_with_learning()
    except KeyboardInterrupt:
        safe_logger.info("MIT Demo interrupted by user")
    except Exception as e:
        safe_logger.error(f"MIT Demo failed: {e}")


if __name__ == "__main__":
    print("[rocket][brain] MIT Emotime Advanced Demo Starting...")
    print("Features: Adaptive Calibration, Deep Learning, Multi-modal Fusion")
    print("Press Ctrl+C to stop\n")
    
    asyncio.run(main())