"""
üåø‚ú® Emotime Feature Fusion ‚Äî –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

–§—å—é–∂–Ω —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å —Ä–∞–∑–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤ –≤ –µ–¥–∏–Ω—ã–µ
—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: –≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å, –≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ, –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ç–µ–º–ø, –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å.

"–ö–∞–∫ —á—É–≤—Å—Ç–≤–∞ —Å–ª–∏–≤–∞—é—Ç—Å—è –≤ –æ–¥–Ω—É –º–µ–ª–æ–¥–∏—é –¥—É—à–∏"
"""

import asyncio
import numpy as np
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from collections import defaultdict, deque

from .sensors import SensorData, SensorType


@dataclass 
class EmotionalFeatures:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
    valence: float      # -1.0 to 1.0 (–Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–µ ‚Üí –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–µ)
    arousal: float      # 0.0 to 1.0 (—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ ‚Üí –≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ)  
    dominance: float    # 0.0 to 1.0 (–ø–æ–¥—á–∏–Ω–µ–Ω–∏–µ ‚Üí –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
    tempo: float        # 0.0 to 1.0 (–º–µ–¥–ª–µ–Ω–Ω–æ ‚Üí –±—ã—Å—Ç—Ä–æ)
    intensity: float    # 0.0 to 1.0 (—Å–ª–∞–±–æ ‚Üí —Å–∏–ª—å–Ω–æ)
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    timestamp: datetime = None
    confidence: float = 0.0
    sources: List[str] = None  # –∫–∞–∫–∏–µ —Å–µ–Ω—Å–æ—Ä—ã —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏


class FeatureFusion:
    """
    –°–∏—Å—Ç–µ–º–∞ —Ñ—å—é–∂–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ Emotime.
    
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö, —Ç–∞–∫—Ç–∏–ª—å–Ω—ã—Ö –∏ –∞—É–¥–∏–æ —Å–µ–Ω—Å–æ—Ä–æ–≤
    –≤ –µ–¥–∏–Ω—ã–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ
    —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –∏ –≤–µ—Å–æ–≤—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤.
    """
    
    def __init__(
        self,
        text_weight: float = 0.4,
        touch_weight: float = 0.3, 
        audio_weight: float = 0.3,
        smoothing_alpha: float = 0.7,  # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç EWMA
        history_window: int = 50       # —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏
    ):
        self.weights = {
            SensorType.TEXT: text_weight,
            SensorType.TOUCH: touch_weight,
            SensorType.AUDIO: audio_weight
        }
        
        self.smoothing_alpha = smoothing_alpha
        self.history_window = history_window
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.feature_history: deque = deque(maxlen=history_window)
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è EWMA
        self.last_features: Optional[EmotionalFeatures] = None
        
        # –ë—É—Ñ–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–Ω—Å–æ—Ä–æ–≤ (–¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤ –±–∞—Ç—á–∏)
        self.sensor_buffers: Dict[SensorType, deque] = {
            SensorType.TEXT: deque(maxlen=10),
            SensorType.TOUCH: deque(maxlen=20),
            SensorType.AUDIO: deque(maxlen=5)
        }
    
    async def process_batch(self, sensor_data_list: List[SensorData]) -> Optional[EmotionalFeatures]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö —Å —Å–µ–Ω—Å–æ—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏.
        
        Args:
            sensor_data_list: –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤
            
        Returns:
            –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        """
        if not sensor_data_list:
            return None
            
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º —Å–µ–Ω—Å–æ—Ä–æ–≤
        sensor_groups = defaultdict(list)
        for data in sensor_data_list:
            sensor_groups[data.sensor_type].append(data)
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Å–µ–Ω—Å–æ—Ä–æ–≤
        sensor_features = {}
        active_sources = []
        
        for sensor_type, data_list in sensor_groups.items():
            features = await self._extract_sensor_features(sensor_type, data_list)
            if features:
                sensor_features[sensor_type] = features
                active_sources.append(sensor_type.value)
        
        if not sensor_features:
            return None
            
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        fused_features = await self._fuse_features(sensor_features, active_sources)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
        smoothed_features = await self._apply_smoothing(fused_features)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.feature_history.append(smoothed_features)
        self.last_features = smoothed_features
        
        return smoothed_features
    
    async def _extract_sensor_features(
        self, 
        sensor_type: SensorType, 
        data_list: List[SensorData]
    ) -> Optional[Dict[str, float]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å–µ–Ω—Å–æ—Ä–∞."""
        
        if not data_list:
            return None
            
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ–≥–æ —Ç–∏–ø–∞
        all_metadata = {}
        for data in data_list:
            all_metadata.update(data.metadata)
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        base_features = {
            "valence": all_metadata.get("valence", 0.0),
            "arousal": all_metadata.get("arousal", 0.0), 
            "intensity": all_metadata.get("intensity", 0.0)
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è —Å–µ–Ω—Å–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏
        if sensor_type == SensorType.TEXT:
            return await self._process_text_features(data_list, base_features)
        elif sensor_type == SensorType.TOUCH:
            return await self._process_touch_features(data_list, base_features)
        elif sensor_type == SensorType.AUDIO:
            return await self._process_audio_features(data_list, base_features)
            
        return base_features
    
    async def _process_text_features(
        self, 
        data_list: List[SensorData], 
        base_features: Dict[str, float]
    ) -> Dict[str, float]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–º–ø –ø–µ—á–∞—Ç–∏
        total_chars = 0
        total_time = 0
        pause_times = []
        
        for data in data_list:
            text_data = data.raw_data
            total_chars += text_data.char_count
            
            if text_data.typing_speed:
                total_time += text_data.char_count / text_data.typing_speed
                
            if text_data.pause_duration:
                pause_times.append(text_data.pause_duration)
                
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π —Ç–µ–º–ø
        if total_time > 0:
            avg_typing_speed = total_chars / total_time
            tempo = min(avg_typing_speed / 10.0, 1.0)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 10 —Å–∏–º–≤–æ–ª–∞–º/—Å–µ–∫
        else:
            tempo = 0.5
            
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—É–∑—ã (–≤–ª–∏—è—é—Ç –Ω–∞ –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
        if pause_times:
            avg_pause = np.mean(pause_times)
            # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—É–∑—ã = —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –¥–ª–∏–Ω–Ω—ã–µ = –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            dominance = max(0.0, 1.0 - min(avg_pause / 10.0, 1.0))
        else:
            dominance = 0.5
            
        return {
            **base_features,
            "tempo": tempo,
            "dominance": dominance
        }
    
    async def _process_touch_features(
        self, 
        data_list: List[SensorData],
        base_features: Dict[str, float]
    ) -> Dict[str, float]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–∞–∫—Ç–∏–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
        
        pressures = []
        frequencies = []
        durations = []
        
        for data in data_list:
            touch_data = data.raw_data
            pressures.append(touch_data.pressure)
            frequencies.append(touch_data.frequency)
            durations.append(touch_data.duration)
            
        # –¢–µ–º–ø –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã –∫–∞—Å–∞–Ω–∏–π
        avg_frequency = np.mean(frequencies) if frequencies else 0
        tempo = min(avg_frequency / 60.0, 1.0)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 60 –∫–∞—Å–∞–Ω–∏—è–º/–º–∏–Ω
        
        # –î–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∏–ª—ã –Ω–∞–∂–∞—Ç–∏–π
        avg_pressure = np.mean(pressures) if pressures else 0.5
        dominance = min(avg_pressure, 1.0)
        
        return {
            **base_features,
            "tempo": tempo,
            "dominance": dominance
        }
    
    async def _process_audio_features(
        self,
        data_list: List[SensorData],
        base_features: Dict[str, float]  
    ) -> Dict[str, float]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –ø—Ä–∏–∑–Ω–∞–∫–∏."""
        
        speech_rates = []
        volumes = []
        pitch_variances = []
        
        for data in data_list:
            audio_data = data.raw_data
            speech_rates.append(audio_data.speech_rate)
            volumes.append(audio_data.volume_level)
            pitch_variances.append(audio_data.pitch_variance)
            
        # –¢–µ–º–ø –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–µ—á–∏
        avg_speech_rate = np.mean(speech_rates) if speech_rates else 150
        tempo = min(avg_speech_rate / 200.0, 1.0)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 200 —Å–ª–æ–≤/–º–∏–Ω
        
        # –î–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –∏ –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ç–æ–Ω–∞
        avg_volume = np.mean(volumes) if volumes else 0.5
        avg_variance = np.mean(pitch_variances) if pitch_variances else 25
        
        dominance = (avg_volume + min(avg_variance / 50.0, 1.0)) / 2.0
        
        return {
            **base_features,
            "tempo": tempo, 
            "dominance": dominance
        }
    
    async def _fuse_features(
        self, 
        sensor_features: Dict[SensorType, Dict[str, float]],
        active_sources: List[str]
    ) -> EmotionalFeatures:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å —Ä–∞–∑–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤."""
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ —Å—É–º–º—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        weighted_features = {
            "valence": 0.0,
            "arousal": 0.0,
            "dominance": 0.0,
            "tempo": 0.0,
            "intensity": 0.0
        }
        
        total_weight = 0.0
        
        for sensor_type, features in sensor_features.items():
            weight = self.weights[sensor_type]
            total_weight += weight
            
            for feature_name in weighted_features:
                if feature_name in features:
                    weighted_features[feature_name] += features[feature_name] * weight
                    
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ –æ–±—â–µ–º—É –≤–µ—Å—É
        if total_weight > 0:
            for feature_name in weighted_features:
                weighted_features[feature_name] /= total_weight
                
        # –í—ã—á–∏—Å–ª—è–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤
        confidence = len(sensor_features) / len(self.weights)
        
        return EmotionalFeatures(
            valence=max(-1.0, min(1.0, weighted_features["valence"])),
            arousal=max(0.0, min(1.0, weighted_features["arousal"])),
            dominance=max(0.0, min(1.0, weighted_features["dominance"])),
            tempo=max(0.0, min(1.0, weighted_features["tempo"])),
            intensity=max(0.0, min(1.0, weighted_features["intensity"])),
            timestamp=datetime.now(),
            confidence=confidence,
            sources=active_sources
        )
    
    async def _apply_smoothing(self, new_features: EmotionalFeatures) -> EmotionalFeatures:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º."""
        
        if not self.last_features:
            return new_features
            
        # –ü—Ä–∏–º–µ–Ω—è–µ–º EWMA (Exponential Weighted Moving Average)
        alpha = self.smoothing_alpha
        
        smoothed = EmotionalFeatures(
            valence=alpha * new_features.valence + (1 - alpha) * self.last_features.valence,
            arousal=alpha * new_features.arousal + (1 - alpha) * self.last_features.arousal,
            dominance=alpha * new_features.dominance + (1 - alpha) * self.last_features.dominance,
            tempo=alpha * new_features.tempo + (1 - alpha) * self.last_features.tempo,
            intensity=alpha * new_features.intensity + (1 - alpha) * self.last_features.intensity,
            timestamp=new_features.timestamp,
            confidence=new_features.confidence,
            sources=new_features.sources
        )
        
        return smoothed
    
    def get_feature_statistics(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º –¥–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
        if not self.feature_history:
            return {"status": "no_data"}
            
        history = list(self.feature_history)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        valences = [f.valence for f in history]
        arousals = [f.arousal for f in history]
        
        return {
            "total_points": len(history),
            "valence": {
                "mean": np.mean(valences),
                "std": np.std(valences),
                "min": np.min(valences),
                "max": np.max(valences)
            },
            "arousal": {
                "mean": np.mean(arousals),
                "std": np.std(arousals),
                "min": np.min(arousals),
                "max": np.max(arousals)
            },
            "recent_confidence": history[-1].confidence if history else 0.0,
            "active_sources": history[-1].sources if history else []
        }