"""
Quick Performance Optimizations for LIMINAL
–ë—ã—Å—Ç—Ä—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º.
"""

import asyncio
import time
import requests
from datetime import datetime


class QuickPerformanceTest:
    """–ë—ã—Å—Ç—Ä–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
    
    def run_quick_analysis(self):
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º."""
        print("QUICK PERFORMANCE ANALYSIS")
        print("=" * 40)
        
        # 1. Response time test
        print("1. Response Time Analysis")
        print("-" * 25)
        
        endpoints = ["/health", "/emotime/status", "/metrics"]
        for endpoint in endpoints:
            avg_time = self._measure_response_time(endpoint)
            status = "OK" if avg_time < 2000 else "SLOW"
            print(f"   {endpoint}: {avg_time:.0f}ms [{status}]")
        
        # 2. Emotime confidence test
        print(f"\n2. Emotime Confidence Test")
        print("-" * 25)
        
        confidence = self._test_emotime_confidence()
        status = "OK" if confidence > 0.5 else "LOW"
        print(f"   Average confidence: {confidence:.2f} [{status}]")
        
        # 3. Simple throughput test
        print(f"\n3. Basic Throughput Test")
        print("-" * 25)
        
        throughput = self._test_basic_throughput()
        status = "OK" if throughput > 10 else "LOW"
        print(f"   Throughput: {throughput:.1f} req/sec [{status}]")
        
        print(f"\nAnalysis completed: {datetime.now().strftime('%H:%M:%S')}")
    
    def _measure_response_time(self, endpoint: str, samples: int = 3) -> float:
        """–ò–∑–º–µ—Ä—è–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ endpoint."""
        times = []
        
        for _ in range(samples):
            start = time.time()
            try:
                response = requests.get(f"{self.base_url}{endpoint}", timeout=5)
                if response.status_code == 200:
                    times.append((time.time() - start) * 1000)
                else:
                    times.append(5000)  # Penalty for errors
            except:
                times.append(5000)  # Penalty for timeout
        
        return sum(times) / len(times) if times else 5000
    
    def _test_emotime_confidence(self) -> float:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å Emotime –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        confidences = []
        
        test_texts = [
            "I feel happy and energetic!",
            "This makes me sad and worried",
            "I'm in a peaceful state of mind"
        ]
        
        for text in test_texts:
            try:
                response = requests.post(
                    f"{self.base_url}/emotime/text",
                    json={
                        "text": text,
                        "user_id": "quick_test_user",
                        "session_id": "quick_session"
                    },
                    timeout=8
                )
                
                if response.status_code == 200:
                    data = response.json()
                    confidence = data.get("confidence", 0.0)
                    confidences.append(confidence)
                else:
                    confidences.append(0.0)
                    
            except Exception:
                confidences.append(0.0)
        
        return sum(confidences) / len(confidences) if confidences else 0.0
    
    def _test_basic_throughput(self) -> float:
        """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏."""
        start_time = time.time()
        request_count = 0
        success_count = 0
        test_duration = 5.0  # 5 seconds
        
        while (time.time() - start_time) < test_duration:
            try:
                response = requests.get(f"{self.base_url}/health", timeout=1)
                request_count += 1
                if response.status_code == 200:
                    success_count += 1
            except:
                request_count += 1
            
            # Small delay to prevent overwhelming
            time.sleep(0.1)
        
        actual_duration = time.time() - start_time
        return success_count / actual_duration


def create_performance_optimizations():
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª—ã —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    
    # 1. Caching layer –¥–ª—è Emotime
    caching_code = '''"""
Emotime Performance Optimizations - Caching Layer
–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ Emotime.
"""

import hashlib
import time
from typing import Dict, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class CacheEntry:
    """–ó–∞–ø–∏—Å—å –≤ –∫—ç—à–µ."""
    data: Any
    timestamp: datetime
    ttl_seconds: int
    
    @property
    def is_expired(self) -> bool:
        return datetime.now() > (self.timestamp + timedelta(seconds=self.ttl_seconds))


class EmotimeCacheManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –¥–ª—è Emotime –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    
    def __init__(self, max_size: int = 1000, default_ttl: int = 300):
        self.cache: Dict[str, CacheEntry] = {}
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.hits = 0
        self.misses = 0
    
    def get_cache_key(self, text: str, user_id: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        content = f"{user_id}:{text}".encode('utf-8')
        return hashlib.md5(content).hexdigest()
    
    def get(self, cache_key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞."""
        entry = self.cache.get(cache_key)
        
        if entry is None:
            self.misses += 1
            return None
        
        if entry.is_expired:
            del self.cache[cache_key]
            self.misses += 1
            return None
        
        self.hits += 1
        return entry.data
    
    def set(self, cache_key: str, data: Any, ttl: Optional[int] = None) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à."""
        if len(self.cache) >= self.max_size:
            self._evict_oldest()
        
        entry = CacheEntry(
            data=data,
            timestamp=datetime.now(),
            ttl_seconds=ttl or self.default_ttl
        )
        
        self.cache[cache_key] = entry
    
    def _evict_oldest(self):
        """–£–¥–∞–ª—è–µ—Ç —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –∑–∞–ø–∏—Å—å."""
        if self.cache:
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k].timestamp)
            del self.cache[oldest_key]
    
    def get_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞."""
        total_requests = self.hits + self.misses
        hit_rate = (self.hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "size": len(self.cache),
            "max_size": self.max_size,
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate_percent": hit_rate,
            "memory_usage_percent": (len(self.cache) / self.max_size * 100)
        }
    
    def clear_expired(self):
        """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–µ–∫—à–∏–µ –∑–∞–ø–∏—Å–∏."""
        expired_keys = [k for k, v in self.cache.items() if v.is_expired]
        for key in expired_keys:
            del self.cache[key]
        return len(expired_keys)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫—ç—à–∞
emotime_cache = EmotimeCacheManager()
'''
    
    with open("C:\\Users\\safal\\OneDrive\\Documente\\GitHub\\resonance-liminal\\backend\\emotime\\cache.py", "w") as f:
        f.write(caching_code)
    
    print("‚úÖ Created: emotime/cache.py")
    
    # 2. Batch processing –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è throughput
    batch_processing_code = '''"""
Batch Processing Optimizations
–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.
"""

import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from dataclasses import dataclass

@dataclass
class BatchRequest:
    """–ó–∞–ø—Ä–æ—Å –≤ –±–∞—Ç—á–µ."""
    id: str
    data: Dict[str, Any]
    timestamp: datetime
    future: asyncio.Future


class BatchProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    
    def __init__(self, batch_size: int = 10, batch_timeout: float = 1.0):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.pending_requests: List[BatchRequest] = []
        self._processing_lock = asyncio.Lock()
        self._batch_task: Optional[asyncio.Task] = None
    
    async def add_request(self, request_id: str, data: Dict[str, Any]) -> Any:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ –±–∞—Ç—á –∏ –æ–∂–∏–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
        future = asyncio.Future()
        
        request = BatchRequest(
            id=request_id,
            data=data,
            timestamp=datetime.now(),
            future=future
        )
        
        async with self._processing_lock:
            self.pending_requests.append(request)
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ –µ—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞
            if len(self.pending_requests) >= self.batch_size:
                await self._process_batch()
            elif self._batch_task is None:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ timeout
                self._batch_task = asyncio.create_task(self._batch_timeout_handler())
        
        # –û–∂–∏–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return await future
    
    async def _batch_timeout_handler(self):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ timeout –¥–ª—è –±–∞—Ç—á–∞."""
        await asyncio.sleep(self.batch_timeout)
        
        async with self._processing_lock:
            if self.pending_requests:
                await self._process_batch()
    
    async def _process_batch(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –±–∞—Ç—á –∑–∞–ø—Ä–æ—Å–æ–≤."""
        if not self.pending_requests:
            return
        
        batch_to_process = self.pending_requests.copy()
        self.pending_requests.clear()
        
        if self._batch_task:
            self._batch_task.cancel()
            self._batch_task = None
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –±–∞—Ç—á–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
            results = await self._process_batch_data(batch_to_process)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–∞–∂–¥–æ–º—É –∑–∞–ø—Ä–æ—Å—É
            for request, result in zip(batch_to_process, results):
                if not request.future.done():
                    request.future.set_result(result)
                    
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –≤—Å–µ–º –∑–∞–ø—Ä–æ—Å–∞–º
            for request in batch_to_process:
                if not request.future.done():
                    request.future.set_exception(e)
    
    async def _process_batch_data(self, batch: List[BatchRequest]) -> List[Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞. –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö."""
        # –ó–∞–≥–ª—É—à–∫–∞ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞ Emotime
        results = []
        for request in batch:
            # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            await asyncio.sleep(0.1)
            results.append({
                "id": request.id,
                "processed_at": datetime.now().isoformat(),
                "data": request.data
            })
        return results


class EmotimeBatchProcessor(BatchProcessor):
    """–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–∞—Ç—á –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è Emotime."""
    
    def __init__(self, emotime_engine=None, batch_size: int = 5, batch_timeout: float = 0.5):
        super().__init__(batch_size, batch_timeout)
        self.emotime_engine = emotime_engine
    
    async def _process_batch_data(self, batch: List[BatchRequest]) -> List[Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        if not self.emotime_engine:
            # Fallback –±–µ–∑ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            return await super()._process_batch_data(batch)
        
        results = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –¥–ª—è –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        user_groups = {}
        for request in batch:
            user_id = request.data.get("user_id", "default")
            if user_id not in user_groups:
                user_groups[user_id] = []
            user_groups[user_id].append(request)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
        for user_id, user_requests in user_groups.items():
            for request in user_requests:
                try:
                    # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Emotime
                    result = await self._process_single_emotime_request(request)
                    results.append(result)
                except Exception as e:
                    results.append({"error": str(e), "id": request.id})
        
        return results
    
    async def _process_single_emotime_request(self, request: BatchRequest) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π Emotime –∑–∞–ø—Ä–æ—Å."""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º Emotime –¥–≤–∏–∂–∫–æ–º
        text = request.data.get("text", "")
        user_id = request.data.get("user_id", "")
        
        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ —Ä–µ–∞–ª—å–Ω–æ–≥–æ Emotime API
        return {
            "id": request.id,
            "emotional_features": {
                "valence": 0.7,  # –ó–∞–≥–ª—É—à–∫–∞
                "arousal": 0.5,
                "dominance": 0.6
            },
            "confidence": 0.8,
            "processed_at": datetime.now().isoformat()
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –±–∞—Ç—á –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
emotime_batch_processor = EmotimeBatchProcessor()
'''
    
    with open("C:\\Users\\safal\\OneDrive\\Documente\\GitHub\\resonance-liminal\\backend\\performance\\batch_processor.py", "w") as f:
        f.write(batch_processing_code)
    
    print("‚úÖ Created: performance/batch_processor.py")
    
    # 3. Connection pooling –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    connection_pool_code = '''"""
Connection Pooling Optimizations
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—É–ª–æ–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import asyncio
import aiohttp
import time
from typing import Optional, Dict, Any
from contextlib import asynccontextmanager

class OptimizedConnectionManager:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π."""
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
        self.connector: Optional[aiohttp.TCPConnector] = None
        
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
        if self.session is None:
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π TCP –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä
            self.connector = aiohttp.TCPConnector(
                limit=100,              # –û–±—â–∏–π –ª–∏–º–∏—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
                limit_per_host=30,      # –õ–∏–º–∏—Ç –Ω–∞ —Ö–æ—Å—Ç
                ttl_dns_cache=300,      # DNS –∫—ç—à –Ω–∞ 5 –º–∏–Ω—É—Ç
                use_dns_cache=True,
                keepalive_timeout=30,   # Keep-alive timeout
                enable_cleanup_closed=True
            )
            
            # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è
            timeout = aiohttp.ClientTimeout(
                total=10,               # –û–±—â–∏–π timeout
                connect=2,              # Timeout –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                sock_read=5             # Timeout —á—Ç–µ–Ω–∏—è
            )
            
            self.session = aiohttp.ClientSession(
                connector=self.connector,
                timeout=timeout,
                headers={
                    'Connection': 'keep-alive',
                    'Accept-Encoding': 'gzip, deflate'
                }
            )
    
    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
        if self.session:
            await self.session.close()
        if self.connector:
            await self.connector.close()
    
    @asynccontextmanager
    async def get_session(self):
        """Context manager –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏."""
        await self.initialize()
        try:
            yield self.session
        finally:
            # –°–µ—Å—Å–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç–æ–π –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            pass


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
connection_manager = OptimizedConnectionManager()


class RedisConnectionOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è Redis —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π."""
    
    @staticmethod
    def get_optimized_redis_config() -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Redis."""
        return {
            # Connection pooling
            "connection_pool_max_connections": 50,
            "connection_pool_retry_on_timeout": True,
            
            # Timeouts
            "socket_connect_timeout": 2,
            "socket_timeout": 5,
            "socket_keepalive": True,
            "socket_keepalive_options": {},
            
            # Protocol optimizations
            "protocol": 3,
            "encoding": "utf-8",
            "decode_responses": True,
            
            # Performance settings
            "max_connections": 50,
            "retry_on_timeout": True,
            "health_check_interval": 30
        }
    
    @staticmethod
    def get_redis_lua_scripts() -> Dict[str, str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ Lua —Å–∫—Ä–∏–ø—Ç—ã –¥–ª—è Redis."""
        return {
            # –ê—Ç–æ–º–∞—Ä–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è rate limiting
            "rate_limit": """
local key = KEYS[1]
local window = tonumber(ARGV[1])
local limit = tonumber(ARGV[2])
local current_time = tonumber(ARGV[3])

local current = redis.call('GET', key)
if current == false then
    redis.call('SET', key, 1)
    redis.call('EXPIRE', key, window)
    return {1, limit}
end

current = tonumber(current)
if current < limit then
    current = redis.call('INCR', key)
    local ttl = redis.call('TTL', key)
    if ttl == -1 then
        redis.call('EXPIRE', key, window)
    end
    return {current, limit}
else
    local ttl = redis.call('TTL', key)
    return {current, limit, ttl}
end
            """,
            
            # Batch –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–µ—Ç—Ä–∏–∫
            "batch_metrics": """
local metrics = cjson.decode(ARGV[1])
local results = {}

for key, value in pairs(metrics) do
    local result = redis.call('INCRBY', key, value)
    table.insert(results, {key, result})
end

return results
            """
        }


class DatabaseOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    
    @staticmethod
    def get_neo4j_optimized_config() -> Dict[str, Any]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Neo4j."""
        return {
            "uri": "bolt://localhost:7687",
            "max_connection_pool_size": 50,
            "max_transaction_retry_time": 30,
            "connection_acquisition_timeout": 5,
            "trust": "TRUST_ALL_CERTIFICATES",
            "encrypted": False,
            
            # Performance settings
            "fetch_size": 1000,
            "max_connection_lifetime": 300,  # 5 minutes
            "connection_timeout": 5,
            "keep_alive": True
        }
    
    @staticmethod
    def get_optimized_queries() -> Dict[str, str]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ Cypher –∑–∞–ø—Ä–æ—Å—ã."""
        return {
            "create_emotional_point": """
MERGE (u:User {user_id: $user_id})
CREATE (p:EmotionalPoint {
    point_id: $point_id,
    valence: $valence,
    arousal: $arousal,
    dominance: $dominance,
    timestamp: $timestamp,
    session_id: $session_id
})
CREATE (u)-[:HAS_EMOTIONAL_STATE]->(p)
RETURN p.point_id as point_id
            """,
            
            "get_user_emotional_history": """
MATCH (u:User {user_id: $user_id})-[:HAS_EMOTIONAL_STATE]->(p:EmotionalPoint)
WHERE p.timestamp > $since
RETURN p
ORDER BY p.timestamp DESC
LIMIT $limit
            """
        }
'''
    
    with open("C:\\Users\\safal\\OneDrive\\Documente\\GitHub\\resonance-liminal\\backend\\performance\\connection_optimizations.py", "w") as f:
        f.write(connection_pool_code)
    
    print("‚úÖ Created: performance/connection_optimizations.py")


def main():
    """–°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç."""
    print("PERFORMANCE OPTIMIZATION SETUP")
    print("=" * 40)
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
    print("\n1. Creating optimization files...")
    create_performance_optimizations()
    
    print("\n2. Running quick performance test...")
    tester = QuickPerformanceTest()
    tester.run_quick_analysis()
    
    print(f"\n3. OPTIMIZATION RECOMMENDATIONS:")
    print("   1. ‚úÖ Implement emotime/cache.py for response caching")
    print("   2. ‚úÖ Use performance/batch_processor.py for throughput") 
    print("   3. ‚úÖ Apply connection_optimizations.py for DB performance")
    print("   4. üîß Configure Redis connection pooling")
    print("   5. üîß Enable Neo4j query optimization")
    print("   6. üîß Add response compression (gzip)")
    
    print(f"\nNext steps:")
    print("   - Integrate caching in Emotime API endpoints")
    print("   - Replace single requests with batch processing")
    print("   - Apply connection pool configurations")
    print("   - Test improvements with load testing")


if __name__ == "__main__":
    main()