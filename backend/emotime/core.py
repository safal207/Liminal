"""
üåø‚ú® Emotime Core Engine ‚Äî —Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫ Emotime, –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É—é—â–∏–π –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- –°–µ–Ω—Å–æ—Ä–Ω—ã–π —Å–ª–æ–π (—Ç–µ–∫—Å—Ç, –∫–∞—Å–∞–Ω–∏—è, –∞—É–¥–∏–æ)  
- –§—å—é–∂–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤–∞–ª–µ–Ω—Ç–Ω–æ—Å—Ç—å, –≤–æ–∑–±—É–∂–¥–µ–Ω–∏–µ, —Ç–µ–º–ø)
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –∏ —Ä–µ–∂–∏–º—ã (—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ, —Ñ–æ–∫—É—Å, —Å—Ç—Ä–µ—Å—Å)
"""

import asyncio
import time
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

from .sensors import SensorData
from .fusion import FeatureFusion, EmotionalFeatures
from .timeseries import EmotionalTimeSeries, EmotionalPoint
from .modes import EmotionalModes, EmotionalMode
from .metrics_integration import emotime_metrics
from .neo4j_storage import EmotimeNeo4jStorage
from .utils import safe_logger

# MIT Advanced ML components
try:
    from .ml import (
        get_calibrator, AdaptiveCalibrator,
        get_adaptive_engine, AdaptiveEmotionalEngine,
        get_feature_learner, DeepFeatureLearner,
        ADAPTIVE_ENGINE_AVAILABLE, FEATURE_LEARNING_AVAILABLE
    )
    ML_ENHANCED = True
except ImportError:
    ML_ENHANCED = False
    ADAPTIVE_ENGINE_AVAILABLE = False
    FEATURE_LEARNING_AVAILABLE = False
    safe_logger.warning("ML enhancements not available - using classical algorithms")


@dataclass
class EmotimeState:
    """–¢–µ–∫—É—â–µ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã."""
    timestamp: datetime
    features: EmotionalFeatures
    mode: EmotionalMode
    resonance_trace: List[EmotionalPoint]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Ç–æ—á–µ–∫
    confidence: float = 0.0


class EmotimeEngine:
    """
    –ì–ª–∞–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ Emotime ‚Äî —Å–µ—Ä–¥—Ü–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.
    
    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–æ—Ç–æ–∫:
    —Å–µ–Ω—Å–æ—Ä—ã ‚Üí —Ñ—å—é–∂–Ω ‚Üí –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã ‚Üí —Ä–µ–∂–∏–º—ã ‚Üí —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–µ–¥
    """
    
    def __init__(
        self,
        user_id: str = "default_user",
        session_id: str = None,
        trace_window: int = 100,  # —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω–æ–≥–æ —Å–ª–µ–¥–∞
        update_interval: float = 1.0,  # –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        enable_neo4j: bool = True,  # –≤–∫–ª—é—á–∏—Ç—å Neo4j —Ö—Ä–∞–Ω–µ–Ω–∏–µ
        enable_ml: bool = True,  # –≤–∫–ª—é—á–∏—Ç—å MIT ML enhancements
    ):
        self.user_id = user_id
        self.session_id = session_id or f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.trace_window = trace_window
        self.update_interval = update_interval
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.fusion = FeatureFusion()
        self.timeseries = EmotionalTimeSeries()
        self.modes = EmotionalModes()
        
        # Neo4j —Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.storage = EmotimeNeo4jStorage() if enable_neo4j else None
        
        # MIT ML enhancements
        if enable_ml and ML_ENHANCED:
            # –ö–∞–ª–∏–±—Ä–∞—Ç–æ—Ä –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω (–±–µ–∑ sklearn)
            self.calibrator = get_calibrator(user_id)
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω sklearn
            if ADAPTIVE_ENGINE_AVAILABLE and get_adaptive_engine:
                self.adaptive_engine = get_adaptive_engine(user_id)
            else:
                self.adaptive_engine = None
                
            # Feature learner –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω sklearn
            if FEATURE_LEARNING_AVAILABLE and get_feature_learner:
                self.feature_learner = get_feature_learner(user_id)
            else:
                self.feature_learner = None
            
            safe_logger.info(f"MIT ML enabled: calibrator=True, adaptive={self.adaptive_engine is not None}, features={self.feature_learner is not None}")
        else:
            self.calibrator = None
            self.adaptive_engine = None
            self.feature_learner = None
            if enable_ml:
                safe_logger.warning("ML requested but not available")
        
        # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.current_state: Optional[EmotimeState] = None
        self.is_running = False
        
        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å–µ–Ω—Å–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        self._sensor_buffer: List[SensorData] = []
        
        # –î–ª—è —Å–≤—è–∑—ã–≤–∞–Ω–∏—è —Ç–æ—á–µ–∫ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        self._last_point_id: Optional[str] = None
        
    async def start(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –¥–≤–∏–∂–æ–∫ Emotime."""
        self.is_running = True
        safe_logger.info("Engine started - heartbeat begins")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏
        asyncio.create_task(self._heartbeat_loop())
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –¥–≤–∏–∂–æ–∫ Emotime."""
        self.is_running = False
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Neo4j
        if self.storage:
            self.storage.close()
            
        safe_logger.info("Engine stopped - heart stops")
    
    async def process_sensor_data(self, sensor_data: SensorData):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Å–µ–Ω—Å–æ—Ä–æ–≤.
        
        Args:
            sensor_data: –î–∞–Ω–Ω—ã–µ —Å —Å–µ–Ω—Å–æ—Ä–∞ (—Ç–µ–∫—Å—Ç/–∫–∞—Å–∞–Ω–∏–µ/–∞—É–¥–∏–æ)
        """
        self._sensor_buffer.append(sensor_data)
        
    async def get_current_state(self) -> Optional[EmotimeState]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ."""
        return self.current_state
    
    async def get_resonance_trace(self, limit: int = None) -> List[EmotionalPoint]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–µ–¥ (–∏—Å—Ç–æ—Ä–∏—é —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫)."""
        if not self.current_state:
            return []
        
        trace = self.current_state.resonance_trace
        if limit:
            return trace[-limit:]
        return trace
    
    async def _heartbeat_loop(self):
        """
        –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Äî —Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏–µ Emotime.
        
        –ö–∞–∂–¥—ã–π —É–¥–∞—Ä:
        1. –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —Å–µ–Ω—Å–æ—Ä–æ–≤
        2. –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—å—é–∂–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤  
        3. –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
        4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º
        5. –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–µ–¥
        """
        while self.is_running:
            try:
                await self._process_heartbeat()
                await asyncio.sleep(self.update_interval)
                
            except Exception as e:
                safe_logger.error(f"Heartbeat error: {e}")
                await asyncio.sleep(self.update_interval)
    
    async def _process_heartbeat(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ç–∞–∫—Ç —Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏—è."""
        if not self._sensor_buffer:
            return
            
        # 1. –ó–∞–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –±—É—Ñ–µ—Ä–∞
        sensor_data_batch = self._sensor_buffer.copy()
        self._sensor_buffer.clear()
        
        # 2. MIT Enhanced Feature Processing
        if self.feature_learner:
            # Deep feature learning
            deep_features, feature_metadata = await self.feature_learner.process_sensor_batch(sensor_data_batch)
            
            # Traditional fusion for compatibility
            features = await self.fusion.process_batch(sensor_data_batch)
            
            # –ï—Å–ª–∏ deep learning –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥
            if features is None and len(deep_features) > 0:
                # –°–æ–∑–¥–∞–µ–º EmotionalFeatures –∏–∑ deep features
                # –ü—Ä–æ—Å—Ç–æ–µ –º–∞–ø–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                features = EmotionalFeatures(
                    valence=float(np.clip(deep_features[0] if len(deep_features) > 0 else 0.5, 0, 1)),
                    arousal=float(np.clip(deep_features[1] if len(deep_features) > 1 else 0.5, 0, 1)),
                    dominance=float(np.clip(deep_features[2] if len(deep_features) > 2 else 0.5, 0, 1)),
                    tempo=float(np.clip(deep_features[3] if len(deep_features) > 3 else 0.5, 0, 1)),
                    intensity=float(np.clip(deep_features[4] if len(deep_features) > 4 else 0.5, 0, 1)),
                    confidence=float(feature_metadata.get('attention_weights', [0.8])[-1] if feature_metadata.get('attention_weights') else 0.8)
                )
        else:
            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π —Ñ—å—é–∂–Ω –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features = await self.fusion.process_batch(sensor_data_batch)
            
        if not features:
            emotime_metrics.record_heartbeat("no_data")
            return
            
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        emotime_metrics.record_batch_processing(sensor_data_batch, features)
            
        # 3. –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã
        timestamp = datetime.now()
        point = EmotionalPoint(
            timestamp=timestamp,
            valence=features.valence,
            arousal=features.arousal, 
            dominance=features.dominance,
            tempo=features.tempo,
            intensity=features.intensity
        )
        
        self.timeseries.add_point(point)
        
        # 4. MIT Enhanced Emotional Mode Classification
        if self.adaptive_engine:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
            mode, ml_confidence = await self.adaptive_engine.predict_emotional_mode(point)
        else:
            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
            mode = await self.modes.classify_mode(point, self.timeseries)
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–∞ –∏ –ø–∏–∫–æ–≤
        emotime_metrics.record_mode_transition(mode)
        emotime_metrics.record_peak_detection(point)
        emotime_metrics.record_timeseries_points(len(self.timeseries.points))
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Neo4j –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
        if self.storage:
            try:
                point_id = await self.storage.store_emotional_point(
                    user_id=self.user_id,
                    session_id=self.session_id,
                    point=point,
                    mode=mode,
                    previous_point_id=self._last_point_id
                )
                self._last_point_id = point_id
            except Exception as e:
                safe_logger.error(f"Failed to store point in Neo4j: {e}")
        
        # 6. –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω—ã–π —Å–ª–µ–¥
        await self._update_state(features, mode, point)
        
    async def _update_state(
        self, 
        features: EmotionalFeatures, 
        mode: EmotionalMode, 
        new_point: EmotionalPoint
    ):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã."""
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ç–æ—á–∫–∏ –¥–ª—è —Ä–µ–∑–æ–Ω–∞–Ω—Å–Ω–æ–≥–æ —Å–ª–µ–¥–∞
        recent_points = self.timeseries.get_recent_points(self.trace_window)
        
        # –í—ã—á–∏—Å–ª—è–µ–º confidence –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∂–∏–º–∞
        confidence = await self._calculate_confidence(mode, recent_points)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.current_state = EmotimeState(
            timestamp=new_point.timestamp,
            features=features,
            mode=mode,
            resonance_trace=recent_points,
            confidence=confidence
        )
        
        # –í—ã–≤–æ–¥–∏–º —Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏–µ
        await self._emit_heartbeat(mode, confidence)
    
    async def _calculate_confidence(
        self, 
        current_mode: EmotionalMode, 
        recent_points: List[EmotionalPoint]
    ) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ç–µ–∫—É—â–µ–º —Ä–µ–∂–∏–º–µ."""
        if len(recent_points) < 5:
            return 0.5
            
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∂–∏–º–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ç–æ—á–∫–∏
        stable_count = 0
        for point in recent_points[-10:]:  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Ç–æ—á–µ–∫
            point_mode = await self.modes.classify_mode(point, self.timeseries)
            if point_mode.name == current_mode.name:
                stable_count += 1
                
        return min(stable_count / 10.0, 1.0)
    
    async def _emit_heartbeat(self, mode: EmotionalMode, confidence: float):
        """–í—ã–≤–æ–¥–∏—Ç —Å–µ—Ä–¥—Ü–µ–±–∏–µ–Ω–∏–µ –≤ –∫–æ–Ω—Å–æ–ª—å."""
        safe_logger.heartbeat(mode.name.lower(), confidence)
    
    async def get_emotional_insights(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª—É–±–æ–∫–∏–µ –∏–Ω—Å–∞–π—Ç—ã –æ–± —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏."""
        insights = {
            "current_state": self.to_dict(),
            "timeseries_analysis": self.timeseries.to_dict(),
            "mode_statistics": self.modes.get_mode_statistics(),
            "mode_insights": self.modes.get_mode_insights(),
            "fusion_statistics": self.fusion.get_feature_statistics()
        }
        
        # MIT Advanced ML Insights
        if self.calibrator:
            insights["adaptive_calibration"] = self.calibrator.get_calibration_analytics()
            insights["calibrated_thresholds"] = self.calibrator.get_calibrated_thresholds()
            
        if self.adaptive_engine:
            insights["ml_analytics"] = self.adaptive_engine.get_learning_analytics()
            
        if self.feature_learner:
            insights["deep_learning"] = self.feature_learner.get_learned_representations()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Neo4j –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if self.storage:
            try:
                patterns = await self.storage.get_emotional_patterns(self.user_id)
                insights["historical_patterns"] = patterns
            except Exception as e:
                safe_logger.warning(f"Failed to get historical patterns: {e}")
                
        return insights
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è API."""
        if not self.current_state:
            return {"status": "no_data"}
            
        return {
            "status": "active",
            "user_id": self.user_id,
            "session_id": self.session_id,
            "timestamp": self.current_state.timestamp.isoformat(),
            "mode": {
                "name": self.current_state.mode.name,
                "type": self.current_state.mode.type.value,
                "intensity": self.current_state.mode.intensity,
                "description": self.current_state.mode.description,
                "duration": self.current_state.mode.duration
            },
            "features": {
                "valence": self.current_state.features.valence,
                "arousal": self.current_state.features.arousal,
                "dominance": self.current_state.features.dominance,
                "tempo": self.current_state.features.tempo,
                "intensity": self.current_state.features.intensity,
                "confidence": self.current_state.features.confidence
            },
            "confidence": self.current_state.confidence,
            "trace_points": len(self.current_state.resonance_trace),
            "storage_enabled": self.storage is not None,
            "ml_enhanced": self.adaptive_engine is not None
        }
    
    async def learn_from_feedback(
        self, 
        actual_emotion: str, 
        context: Optional[Dict] = None
    ):
        """
        MIT Advanced Learning from User Feedback.
        
        Args:
            actual_emotion: –†–µ–∞–ª—å–Ω–∞—è —ç–º–æ—Ü–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        if not self.adaptive_engine or not self.current_state:
            safe_logger.warning("ML feedback not available - adaptive engine disabled")
            return
        
        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ ModeType
            from .modes import ModeType
            actual_mode = None
            
            for mode_type in ModeType:
                if mode_type.value == actual_emotion.lower():
                    actual_mode = mode_type
                    break
            
            if not actual_mode:
                safe_logger.warning(f"Unknown emotion type: {actual_emotion}")
                return
            
            # –û–±—É—á–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –¥–≤–∏–∂–æ–∫
            last_point = self.current_state.resonance_trace[-1] if self.current_state.resonance_trace else None
            if last_point:
                if self.adaptive_engine:
                    await self.adaptive_engine.learn_from_feedback(last_point, actual_mode, context)
                
                # MIT Calibration: –æ–±—É—á–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–∞—Ç–æ—Ä–∞
                if self.calibrator:
                    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º
                    predicted_mode = self.current_state.mode.type
                    confidence = self.current_state.confidence
                    
                    self.calibrator.add_feedback(
                        emotional_point=last_point,
                        predicted_mode=predicted_mode,
                        actual_mode=actual_mode,
                        confidence=confidence
                    )
                
                safe_logger.info(f"Learned from feedback: {actual_emotion}")
            
        except Exception as e:
            safe_logger.error(f"Learning from feedback failed: {e}")
    
    async def trigger_adaptive_learning(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ."""
        if self.feature_learner:
            await self.feature_learner.update_cross_modal_learning()
            safe_logger.info("Cross-modal learning updated")