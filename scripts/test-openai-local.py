#!/usr/bin/env python
"""
Simple OpenAI integration test for Resonance Liminal project.
This script tests the OpenAI service directly without needing the full ML infrastructure.
"""

import asyncio
import json
import os
import sys
import traceback
from pathlib import Path

print("\n=====================================")
print("   OPENAI INTEGRATION TEST")
print("=====================================\n")

print("1Ô∏è‚É£ Setting up environment...")
# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ sys.path, —á—Ç–æ–±—ã –º—ã –º–æ–≥–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(str(Path(__file__).parent.parent))
print(f"   Added {Path(__file__).parent.parent} to sys.path")
# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
os.environ["PYTHONIOENCODING"] = "utf-8"

print("\n2Ô∏è‚É£ Loading environment variables...")
try:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º .env —Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –µ–≥–æ
    from dotenv import load_dotenv

    env_path = Path(__file__).parent.parent / ".env"
    if env_path.exists():
        load_dotenv(env_path)
        print(f"   ‚úÖ Loaded .env file from {env_path}")
    else:
        print(f"   ‚ö†Ô∏è .env file not found at {env_path}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key and api_key != "demo_key":
        # –°–∫—Ä—ã–≤–∞–µ–º –∫–ª—é—á –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
        masked_key = f"{api_key[:4]}...{api_key[-4:]}"
        print(f"   ‚úÖ Found OpenAI API key: {masked_key}")
    else:
        print(f"   ‚ùå OpenAI API key not set or using demo key: '{api_key}'")
        print("      Please add a valid API key to .env file.")
        sys.exit(1)
except Exception as e:
    print(f"   ‚ùå Error loading environment: {e}")
    traceback.print_exc()
    sys.exit(1)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º OpenAI —Å–µ—Ä–≤–∏—Å
print("\n3Ô∏è‚É£ Importing OpenAI service...")
try:
    from backend.ml.openai_service import OpenAIService, openai_service

    print("   ‚úÖ OpenAI service module imported successfully")
except ImportError as e:
    print(f"   ‚ùå Error importing OpenAI service: {e}")
    print("      Checking for file existence...")

    service_path = Path(__file__).parent.parent / "backend" / "ml" / "openai_service.py"
    if service_path.exists():
        print(f"      ‚úÖ File exists at {service_path}")
        with open(service_path, "r") as f:
            first_lines = "\n".join(f.readlines()[:20])
            print(f"      First lines of file:\n{first_lines}")
    else:
        print(f"      ‚ùå File not found at {service_path}")

    traceback.print_exc()
    sys.exit(1)

# –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
test_features = {
    "messages_per_minute": 120,
    "connection_duration": 3600,
    "error_rate": 0.05,
    "unique_ips": 15,
    "failed_auth_attempts": 3,
}

test_prediction = {
    "anomaly_score": 0.78,
    "is_anomaly": True,
    "confidence": 0.85,
    "threshold": 0.6,
}

# –¢–µ—Å—Ç–æ–≤–æ–µ XAI –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (–∏–º–∏—Ç–∞—Ü–∏—è)
test_xai_explanation = {
    "feature_importances": {
        "messages_per_minute": 0.45,
        "error_rate": 0.35,
        "failed_auth_attempts": 0.15,
        "connection_duration": 0.03,
        "unique_ips": 0.02,
    },
    "method": "shap",
}


async def test_openai_explanation():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç OpenAI API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π"""
    print("\n4Ô∏è‚É£ Testing OpenAI explanation generation...")

    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞
        print("   Checking OpenAI client status...")
        if not hasattr(openai_service, "client") or not openai_service.client:
            print("   ‚ö†Ô∏è OpenAI client not initialized.")
            print("      Initializing OpenAI client with API key...")

            try:
                # –ü—Ä–æ–≤–µ—Ä–∏–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –º–µ—Ç–æ–¥ initialize_client
                if hasattr(openai_service, "initialize_client"):
                    print("      Found initialize_client method, calling it...")
                    openai_service.initialize_client(api_key)
                    print(
                        f"      Client initialized: {openai_service.client is not None}"
                    )
                else:
                    print("      ‚ùå initialize_client method not found!")
                    print("      Available methods/attributes:")
                    for attr in dir(openai_service):
                        if not attr.startswith("_"):
                            print(f"        - {attr}")
                    print("      Creating new instance with explicit API key...")
                    # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
                    temp_service = OpenAIService(api_key=api_key)
                    temp_service.initialize()
                    print(
                        f"      Created new service instance, client status: {temp_service.client is not None}"
                    )
                    # –ó–∞–º–µ–Ω–∏–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
                    openai_service.client = temp_service.client
            except Exception as e:
                print(f"      ‚ùå Error initializing client: {e}")
                traceback.print_exc()
        else:
            print("   ‚úÖ OpenAI client already initialized")

        print("\n   ‚è≥ Requesting natural language explanation from OpenAI...")
        print("      Request params:")
        print(f"      - Model type: anomaly_detection")
        print(f"      - Features: {json.dumps(test_features)[:100]}...")
        print(f"      - Prediction: {json.dumps(test_prediction)[:100]}...")

        try:
            print("      Making API call...")
            result = await openai_service.explain_ml_prediction(
                prediction=test_prediction,
                features=test_features,
                model_type="anomaly_detection",
                xai_explanation=test_xai_explanation,
            )

            print("\n   ‚úÖ Received explanation successfully!")
            if hasattr(result, "summary"):
                print("\n   üîπ Summary:")
                print(f"      {result.summary}")

                print("\n   üîπ Analysis (excerpt):")
                if hasattr(result, "analysis"):
                    print(
                        f"      {result.analysis[:200]}..."
                        if len(result.analysis) > 200
                        else result.analysis
                    )

                print("\n   üîπ Technical Details:")
                if hasattr(result, "technical_details"):
                    print(
                        f"      {json.dumps(result.technical_details, indent=2)[:200]}..."
                        if len(json.dumps(result.technical_details)) > 200
                        else json.dumps(result.technical_details)
                    )

                print("\n   üîπ Recommendations:")
                if hasattr(result, "recommendations"):
                    print(f"      {result.recommendations}")

                print("\n   üîπ Confidence:")
                if hasattr(result, "confidence"):
                    print(f"      {result.confidence}")

                print("\n   ‚úÖ OpenAI integration test PASSED!")
            else:
                print("\n   ‚ùå Result does not have expected structure!")
                print(f"      Result type: {type(result)}")
                print(f"      Result content: {result}")
        except Exception as e:
            print(f"\n   ‚ùå Error during API call: {e}")
            print("      Traceback:")
            traceback.print_exc()

    except Exception as e:
        print(f"\n   ‚ùå Error during OpenAI test: {e}")
        print("\n   Stack trace:")
        traceback.print_exc()
        return False

    return True


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n4Ô∏è‚É£ Preparing test data...")
    print("   ‚úÖ Test data ready")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
    success = await test_openai_explanation()

    print("\n=====================================")
    print("          TEST RESULTS             ")
    print("=====================================\n")

    if success:
        print("‚úÖ All tests passed successfully!")
        print("   XAI + OpenAI integration is working correctly.")
        print("   You can now use the natural language explanations feature.")
    else:
        print("‚ùå Some tests failed. Please check the error messages above.")
        print("   Common issues:")
        print("   1. Invalid or expired OpenAI API key")
        print("   2. Network connection problems")
        print("   3. Mismatched OpenAI client version")
        print("   4. Missing implementation in openai_service.py")
        print("   Try running with debug output: 'python -m backend.ml.openai_service'")

    print("\nüèÅ Test completed")


if __name__ == "__main__":
    asyncio.run(main())
